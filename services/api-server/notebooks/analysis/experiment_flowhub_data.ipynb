{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f491e0db-b6d6-480c-be42-5b1e16ddb1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "  A manager that facilitates reading and writing files to GCP Storage\n",
    "\"\"\"\n",
    "import logging\n",
    "import os\n",
    "import subprocess\n",
    "from io import BytesIO\n",
    "from typing import List, Dict, Callable, Tuple, Union\n",
    "from mypy_extensions import TypedDict\n",
    "\n",
    "from google.cloud import storage # type: ignore\n",
    "\n",
    "def get_path_prefix(root_dir: str, relative_path: str) -> str:\n",
    "    prefix = ''\n",
    "    if root_dir:\n",
    "        prefix = root_dir.rstrip('/') + '/'\n",
    "\n",
    "    if relative_path and relative_path != '/':\n",
    "        prefix = prefix + relative_path.strip('/') + '/'\n",
    "\n",
    "    return prefix\n",
    "\n",
    "class PathNode(TypedDict, total=False):\n",
    "    name: str\n",
    "    type: str\n",
    "    size: float\n",
    "        \n",
    "class GCPStorageManager(object):\n",
    "\n",
    "    def __init__(self, storage_details: Dict, verbose: bool) -> None:\n",
    "        self._bucket_name = storage_details.get('bucket')\n",
    "        self._root_dir = storage_details.get('root')\n",
    "        self.client = storage.Client()\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def _abs_path(self, rel_path: str) -> str:\n",
    "        if not self._root_dir:\n",
    "            return rel_path\n",
    "\n",
    "        return os.path.join(self._root_dir, rel_path)\n",
    "\n",
    "    def _build_current_url(self) -> str:\n",
    "        if self._root_dir:\n",
    "            return \"https://console.cloud.google.com/storage/browser/\" + self._bucket_name + \"/\" + self._root_dir\n",
    "        else:\n",
    "            return \"https://console.cloud.google.com/storage/browser/\" + self._bucket_name\n",
    "\n",
    "    def get_root_dir(self) -> str:\n",
    "        return self._root_dir\n",
    "\n",
    "    def get_storage_details(self) -> Dict:\n",
    "        return {\n",
    "            'provider': file_utils.ProviderList.GCP_STORAGE,\n",
    "            'bucket': self._bucket_name,\n",
    "            'root': self._root_dir\n",
    "        }\n",
    "\n",
    "    def get_sync_login_command(self, env_vars: Dict) -> List[str]:\n",
    "        return None\n",
    "\n",
    "    def get_sync_url(self, path: str) -> str:\n",
    "        if not path or path == '/':\n",
    "            abs_path = self._root_dir\n",
    "        else:\n",
    "            abs_path = self._abs_path(path)\n",
    "        return f'gs://{self._bucket_name}/{abs_path}'\n",
    "\n",
    "    def get_sync_command(self, src_dir: str, remote_path: str) -> Callable:\n",
    "\n",
    "        def sync_call() -> Tuple[int, str]:\n",
    "            cmd = ['gsutil', 'rsync', '-r', src_dir, self.get_sync_url(remote_path)]\n",
    "            p = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "            stdout, stderr = p.communicate()\n",
    "            err_code = 0\n",
    "            stderr_val = ''\n",
    "\n",
    "            if p.returncode != 0:\n",
    "                logging.error('Copy response is: {}'.format(stderr.decode('utf-8')))\n",
    "                stderr_val = stderr.decode('utf-8')\n",
    "                err_code = p.returncode\n",
    "\n",
    "            return err_code, stderr_val\n",
    "\n",
    "        return sync_call\n",
    "\n",
    "    def rm_file(self, relative_path: str) -> None:\n",
    "        bucket = self.client.bucket(self._bucket_name)\n",
    "        path = self._abs_path(relative_path)\n",
    "        blob = bucket.blob(path)\n",
    "        logging.info('Deleting file at ' + path)\n",
    "        blob.delete()\n",
    "\n",
    "    def rm_dir(self, relative_path: str) -> None:\n",
    "        bucket = self.client.bucket(self._bucket_name)\n",
    "        prefix = get_path_prefix(self._root_dir, relative_path)\n",
    "        blob = bucket.blob(prefix)\n",
    "        logging.info('Deleting files at ' + prefix)\n",
    "        blob.delete()\n",
    "\n",
    "    def read_content(self, path: str, throw_exception: bool, read_range: str = None, streaming: bool = False) -> bytes:\n",
    "        try:\n",
    "            path = self._abs_path(path)\n",
    "            bucket = self.client.bucket(self._bucket_name)\n",
    "            blob = bucket.blob(path)\n",
    "            result = blob.download_as_bytes()\n",
    "\n",
    "            if self.verbose:\n",
    "                logging.info(f\"Downloading content from {self._build_current_url()}/{path}\")\n",
    "\n",
    "            return result\n",
    "        except Exception as e:\n",
    "            raise\n",
    "\n",
    "    #def gen_presigned_url(self, path: str) -> str:\n",
    "    #    # dask and other frameworks explicit s3 link rather than a byte stream or contet (e.g. s3://bucket/foo.csv)\n",
    "    #    return self._s3.generate_presigned_url('get_object',\n",
    "    #                                           Params={'Bucket': self._bucket_name, 'Key': self._abs_path(path)})\n",
    "\n",
    "    # Checks to see if the job directory exists.  No side-effects.\n",
    "    def check_dir_exists(self, path: str) -> bool:\n",
    "        # Create the prefix for this particular job.\n",
    "        exists = False\n",
    "        prefix = get_path_prefix(self._root_dir, path)\n",
    "        blobs = list(self.client.list_blobs(\n",
    "            self._bucket_name, prefix=prefix\n",
    "        ))\n",
    "        if len(blobs) > 0:\n",
    "            exists = True\n",
    "\n",
    "        return exists\n",
    "\n",
    "    def _download_content(self, remote_path: str) -> bytes:\n",
    "        remote_path = self._abs_path(remote_path)\n",
    "        bucket = self.client.bucket(self._bucket_name)\n",
    "        blob = bucket.blob(remote_path)\n",
    "        if self.verbose:\n",
    "            logging.info(f\"Downloading content from {self._build_current_url()}/{remote_path}\")\n",
    "\n",
    "        fileobj = BytesIO()\n",
    "        blob.download_to_file(fileobj)\n",
    "        return fileobj.getvalue()\n",
    "\n",
    "    def download_file(self, remote_path: str, file_name: str) -> None:\n",
    "        # Move references to large data items across folders\n",
    "        remote_path = self._abs_path(remote_path)\n",
    "        bucket = self.client.bucket(self._bucket_name)\n",
    "        blob = bucket.blob(remote_path)\n",
    "        if self.verbose:\n",
    "            logging.info(f\"Downloading file {self._build_current_url()}/{remote_path} to {file_name}\")\n",
    "\n",
    "        dirname = os.path.dirname(file_name)\n",
    "\n",
    "        if dirname:\n",
    "            # Only create a directory if it's not ''\n",
    "            if not os.path.exists(dirname):\n",
    "                os.makedirs(dirname)\n",
    "\n",
    "        blob.download_to_filename(file_name)\n",
    "\n",
    "    def download_and_unzip(self, remote_path: str, local_dir: str) -> None:\n",
    "        zip_bytes = self._download_content(remote_path)\n",
    "        file_utils.unzip_into_dir(zip_bytes, local_dir)\n",
    "\n",
    "    def download_dir(self, remote_path: str, local_path: str) -> int:\n",
    "        nFiles = 0\n",
    "        if self.verbose:\n",
    "            logging.info(\"Downloading folder: \" + remote_path + \" to \" + local_path)\n",
    "\n",
    "        prefix = file_utils.get_path_prefix(self._root_dir, remote_path)\n",
    "        for blob in self.client.list_blobs(self._bucket_name, prefix=prefix):\n",
    "            if blob.name.endswith('/'):\n",
    "                continue\n",
    "\n",
    "            rel_path = os.path.relpath(blob.name, prefix)\n",
    "            dest_pathname = os.path.join(local_path, rel_path)\n",
    "\n",
    "            if not os.path.exists(os.path.dirname(dest_pathname)):\n",
    "                os.makedirs(os.path.dirname(dest_pathname))\n",
    "\n",
    "            if self.verbose:\n",
    "                logging.info(f\"Downloading file {blob.name} to {dest_pathname}\")\n",
    "\n",
    "            blob.download_to_filename(dest_pathname)  # Download\n",
    "            nFiles += 1\n",
    "\n",
    "        return nFiles\n",
    "\n",
    "    def upload_content(self, content: bytes, file_name: str) -> None:\n",
    "        # Uploads file content to a specific filename location\n",
    "        bucket = self.client.bucket(self._bucket_name)\n",
    "        if self.verbose:\n",
    "            logging.info(f\"Uploading content to {self._build_current_url()}/{file_name}\")\n",
    "\n",
    "        blob = bucket.blob(self._abs_path(file_name))\n",
    "        blob.upload_from_file(BytesIO(content))\n",
    "\n",
    "    def list_directory(self, path: str, with_size: bool = False) -> Dict:\n",
    "        prefix = get_path_prefix(self._root_dir, path)\n",
    "        bucket = self.client.bucket(self._bucket_name)\n",
    "        blobs = bucket.list_blobs(prefix=prefix)\n",
    "        nodes = []\n",
    "        for blob in blobs:\n",
    "            if blob.name.endswith('/'):\n",
    "                nodes.append(PathNode(name=os.path.basename(blob.name[:-1]), type='folder'))\n",
    "            else:\n",
    "                nodes.append(PathNode(name=os.path.basename(blob.name), type='file'))\n",
    "\n",
    "        return {\n",
    "            'nodes': nodes\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac19077f-ab85-4246-955d-f00e6e0137a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(verbose=True)\n",
    "\n",
    "print(os.environ.get('GOOGLE_APPLICATION_CREDENTIALS'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5d97ba-91e8-41e1-b662-4f97a75810a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "manager = GCPStorageManager({\n",
    "    'bucket': 'partnerships-data-reporting',\n",
    "    'root': ''\n",
    "}, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc08e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "if sys.version_info[0] < 3: \n",
    "    from StringIO import StringIO\n",
    "else:\n",
    "    from io import StringIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d515f4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "directory_contents = manager.list_directory('')['nodes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c5ab12-8eb0-4265-af75-c27cb73bc80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(directory_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6885e8f-c7b7-479e-90ee-e218646a822b",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_contents[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1624c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "company_ids_set = set([])\n",
    "\n",
    "for file_metadata in directory_contents:\n",
    "    file_name = file_metadata['name']\n",
    "    # Company locations file case.\n",
    "    if '_locations.csv' in file_name:\n",
    "        company_id = file_name.replace('_locations.csv', '')\n",
    "        company_ids_set.add(company_id)\n",
    "\n",
    "company_ids = sorted(list(company_ids_set))\n",
    "company_ids_count = len(company_ids)\n",
    "print(f'There are {company_ids_count} companies in the dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037dda03",
   "metadata": {},
   "outputs": [],
   "source": [
    "company_location_ids_set = set([])\n",
    "\n",
    "for index, company_id in enumerate(company_ids):\n",
    "    try:\n",
    "        locations_csv_string = manager.read_content(f'{company_id}/{company_id}_locations.csv', throw_exception=True)\n",
    "        locations_io = StringIO(locations_csv_string.decode(\"utf-8\"))\n",
    "        locations_dataframe = pd.read_csv(locations_io)\n",
    "        for location_index in locations_dataframe.index:\n",
    "            location_id = locations_dataframe['locationId'][location_index]\n",
    "            location_state = locations_dataframe['state'][location_index]\n",
    "            company_location_ids_set.add((company_id, location_id, location_state))\n",
    "    except:\n",
    "        print(f'[{index + 1}] An exception occurred for company ({company_id}) for default path, trying FirstRunWithColorado/ path...')\n",
    "        try:\n",
    "            locations_csv_string = manager.read_content(f'/FirstRunWithColorado/{company_id}/{company_id}_locations.csv', throw_exception=True)\n",
    "            locations_io = StringIO(locations_csv_string.decode(\"utf-8\"))\n",
    "            locations_dataframe = pd.read_csv(locations_io)\n",
    "            for location_index in locations_dataframe.index:\n",
    "                location_id = locations_dataframe['locationId'][location_index]\n",
    "                location_state = locations_dataframe['state'][location_index]\n",
    "                company_location_ids_set.add((company_id, location_id, location_state))\n",
    "        except:\n",
    "            print(f'[{index + 1}] An exception occurred for company ({company_id}) for both paths, skipping...')\n",
    "\n",
    "company_location_ids_count = len(list(company_location_ids_set))\n",
    "print(f'There are {company_location_ids_count} company locations in the dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15b0cd7-7d8b-4bc6-8764-a9dfb0a1b2b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "company_location_ids_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f3e8e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# (company_id, location_id, location_sales_dataframe)\n",
    "company_location_dataframes = []\n",
    "\n",
    "# for index, company_location_tuple in enumerate(list([('4A5DE8Zj5gDtSmCbn', 'JYAZRDbztXRLwJ5r6', 'CO')])):\n",
    "for index, company_location_tuple in enumerate(list(company_location_ids_set)):\n",
    "    company_id, location_id, location_state = company_location_tuple\n",
    "    print(f'[{index + 1}] Downloading dataframes for location ({company_id}, {location_state})')\n",
    "\n",
    "    try:\n",
    "        location_sales_csv_string = manager.read_content(f'{company_id}/{location_id}/{location_id}_sales.csv', throw_exception=True)\n",
    "        location_sales_io = StringIO(location_sales_csv_string.decode(\"utf-8\"))\n",
    "        location_sales_dataframe = pd.read_csv(location_sales_io)\n",
    "        \n",
    "        location_inventory_csv_string = manager.read_content(f'{company_id}/{location_id}/{location_id}_inventory.csv', throw_exception=True)\n",
    "        location_inventory_io = StringIO(location_inventory_csv_string.decode(\"utf-8\"))\n",
    "        location_inventory_dataframe = pd.read_csv(location_inventory_io)\n",
    "\n",
    "        company_location_dataframes.append((company_id, location_state, location_state, location_sales_dataframe, location_inventory_dataframe))\n",
    "    except:\n",
    "        print(f'[{index + 1}] An exception occurred for location ({company_id}, {location_id}, {location_state}) for default path, trying FirstRunWithColorado/ path...')\n",
    "        try:\n",
    "            location_sales_csv_string = manager.read_content(f'/FirstRunWithColorado/{company_id}/{location_id}/{location_id}_sales.csv', throw_exception=True)\n",
    "            location_sales_io = StringIO(location_sales_csv_string.decode(\"utf-8\"))\n",
    "            location_sales_dataframe = pd.read_csv(location_sales_io)\n",
    "\n",
    "            location_inventory_csv_string = manager.read_content(f'/FirstRunWithColorado/{company_id}/{location_id}/{location_id}_inventory.csv', throw_exception=True)\n",
    "            location_inventory_io = StringIO(location_inventory_csv_string.decode(\"utf-8\"))\n",
    "            location_inventory_dataframe = pd.read_csv(location_inventory_io)\n",
    "\n",
    "            company_location_dataframes.append((company_id, location_state, location_state, location_sales_dataframe, location_inventory_dataframe))\n",
    "        except:\n",
    "            print(f'[{index + 1}] An exception occurred for company ({company_id}, {location_id}, {location_state}) for both paths, skipping...')\n",
    "\n",
    "company_location_dataframes_count = len(list(company_location_dataframes))\n",
    "print(f'There are {company_location_dataframes_count} company location dataframes in the dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121ca3a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "state_to_count = {}\n",
    "\n",
    "for company_id, location_id, location_state, location_sales_dataframe, location_inventory_dataframe in company_location_dataframes:\n",
    "    # TODO: do data science stuff on these dataframes.\n",
    "#     print(company_id, location_id, location_state, location_sales_dataframe.shape)\n",
    "    if location_state not in state_to_count:\n",
    "        state_to_count[location_state] = 0\n",
    "    state_to_count[location_state] += 1\n",
    "\n",
    "state_to_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96bb74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for company_id, location_id, location_state, location_sales_dataframe, location_inventory_dataframe in company_location_dataframes:\n",
    "    # TODO: do data science stuff on these dataframes.\n",
    "    print(company_id, location_id, location_state, location_sales_dataframe.shape, location_inventory_dataframe.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f02e11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# company_location_dataframes[0][4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86cf7f50",
   "metadata": {},
   "source": [
    "# PROCESS DATA FRAMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984fc6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de65756",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process_df(df,loc_id,loc_state):\n",
    "    df = (\n",
    "        df\n",
    "        .assign(**{\"SalesCreatedAt\": lambda df_: pd.to_datetime(df_['SalesCreatedAt'])})\n",
    "        .assign(**{\"year_month\": lambda df_: df_['SalesCreatedAt'].dt.strftime('%Y-%m')})\n",
    "        .replace('None', np.nan).fillna(0)\n",
    "    )\n",
    "    #exclude cost < $1.0\n",
    "    df_low_cost = df[df['costInDollars'] < 1.0]\n",
    "    df_non_low_cost = df[df['costInDollars'] >= 1.0]\n",
    "    perc_low_cost = df_low_cost.shape[0] / df.shape[0]\n",
    "    #exclude category = Accessory\n",
    "    df_accessory = df_non_low_cost[df_non_low_cost['category'] == 'Accessory']\n",
    "    df_non_accessory = df_non_low_cost[df_non_low_cost['category'] != 'Accessory']\n",
    "    perc_accessory = df_accessory.shape[0] / df_non_low_cost.shape[0]\n",
    "    # cogs\n",
    "    cogs = df_non_accessory[['year_month','NetSales','costInDollars']].groupby('year_month').sum()\n",
    "    cogs['profit'] = cogs['NetSales'] - cogs['costInDollars']\n",
    "    cogs['margin_perc'] = cogs['profit'] / cogs['NetSales']\n",
    "    cogs['location_id'] = loc_id\n",
    "    cogs['location_state'] = loc_state\n",
    "    return cogs.reset_index(),perc_low_cost,perc_accessory\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a051524",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res = []\n",
    "low_cost_trim_perc= []\n",
    "accessory_trim_perc = []\n",
    "\n",
    "for company_id, location_id, location_state, df in tqdm(company_location_dataframes):\n",
    "    if len(df) == 0:\n",
    "        low_cost_trim_perc.append(np.nan)\n",
    "        accessory_trim_perc.append(np.nan)\n",
    "        continue\n",
    "    res.append(pre_process_df(df, location_id, location_state)[0])\n",
    "    low_cost_trim_perc.append(pre_process_df(df, location_id, location_state)[1])\n",
    "    accessory_trim_perc.append(pre_process_df(df, location_id, location_state)[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21d5636",
   "metadata": {},
   "outputs": [],
   "source": [
    "low_cost_trim_perc_df = pd.DataFrame(low_cost_trim_perc)\n",
    "low_cost_trim_perc_df.columns = ['low_cost_trim_perc']\n",
    "accessory_trim_perc_df = pd.DataFrame(accessory_trim_perc)\n",
    "accessory_trim_perc_df.columns = ['accessory_trim_perc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f980dadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "low_cost_trim_perc_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9cef8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "accessory_trim_perc_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57343896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 178 company locations\n",
    "# 1 failed download -> 177 locations\n",
    "# 15 empty df\n",
    "# 1 company TdyAhrZWq6MDeyNvu: trimmed by accessory and cost > 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2cf455",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.concat(res).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50cbe42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 178 company locations\n",
    "# 1 failed download -> 177 locations\n",
    "# 15 empty df\n",
    "# 1 company TdyAhrZWq6MDeyNvu: trimmed by accessory and cost > 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad7139b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#final_df.to_csv('flowhub_sales_final_df_v0.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee4d7d34",
   "metadata": {},
   "source": [
    "# sanity checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c08a5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#t = company_location_dataframes[0][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2e2c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "#t = t.assign(**{\"SalesCreatedAt\": lambda df_: pd.to_datetime(df_['SalesCreatedAt'])}).assign(**{\"year_month\": lambda df_: df_['SalesCreatedAt'].dt.strftime('%Y-%m')})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74bc973",
   "metadata": {},
   "outputs": [],
   "source": [
    "#t[(t['costInDollars'] >= 1.0)&(t['category'] != 'Accessory')&(t['year_month'] == '2021-05')]['costInDollars'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f65b48",
   "metadata": {},
   "source": [
    "## Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9e872b",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_count = final_df[['location_state','location_id','year_month']].groupby(['location_state','year_month']).count().unstack().T.reset_index()\n",
    "state_count.index = pd.to_datetime(state_count['year_month'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492cb1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = state_count.plot(kind='bar', stacked=True,figsize = (12,9))\n",
    "ax.legend(loc = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcbf901f",
   "metadata": {},
   "source": [
    "# calculate monthly averages by states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd16b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#simple_avg_margin_by_state = final_df[['year_month','margin_perc','location_state']].groupby(['location_state','year_month']).mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced6b497",
   "metadata": {},
   "outputs": [],
   "source": [
    "#simple_avg_margin_by_state.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3752a1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#simple_avg_margin_by_state['year_month'] = pd.to_datetime(simple_avg_margin_by_state['year_month'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58339998",
   "metadata": {},
   "outputs": [],
   "source": [
    "#line,ax = plt.subplots(figsize=(15,10))\n",
    "#plt.ylim([0.7, 0.9])\n",
    "#ax.set_title(\"monthly simple avg margin by state\", fontsize=15)\n",
    "#ax.set_xlabel (\"year month\")\n",
    "#ax.set_ylabel (\"margin %\")\n",
    "#ax.legend (loc=\"upper right\")\n",
    "\n",
    "\n",
    "#sns.lineplot(data=simple_avg_margin_by_state, x=\"year_month\", y=\"margin_perc\", hue=\"location_state\",marker= 'o', markersize=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33132913",
   "metadata": {},
   "outputs": [],
   "source": [
    "#state_count.to_csv('flowhub_sales_state_count_df_v0.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d6c1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#simple_avg_margin_by_state.to_csv('flowhub_sales_state_simple_avg_df_v0.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931660c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#simple_avg_margin_by_state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e9b3ec",
   "metadata": {},
   "source": [
    "## weighted average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab109501",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign an column that gives each location's gmv weight in its (month,state)\n",
    "#final_df = final_df.groupby(['year_month','location_state']).apply(lambda df: df.assign(weight=df['NetSales'] / df['NetSales'].sum())).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0adbd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#weighted_avg_margin_by_state = pd.DataFrame(final_df[['year_month','margin_perc','location_state','weight']].groupby(['location_state','year_month']).apply(lambda x: sum(x['weight']*x['margin_perc'])).reset_index())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc7a997",
   "metadata": {},
   "outputs": [],
   "source": [
    "#weighted_avg_margin_by_state['year_month'] = pd.to_datetime(weighted_avg_margin_by_state['year_month'])\n",
    "#weighted_avg_margin_by_state.columns = ['location_state','year_month','margin_perc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f280f9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#line,ax = plt.subplots(figsize=(15,10))\n",
    "#plt.ylim([0.7, 0.9])\n",
    "#ax.set_title(\"monthly weighted avg margin by state\", fontsize=15)\n",
    "#ax.set_xlabel (\"year month\")\n",
    "#ax.set_ylabel (\"margin %\")\n",
    "#ax.legend (loc=\"upper right\")\n",
    "#sns.lineplot(data=weighted_avg_margin_by_state, x=\"year_month\", y=\"margin_perc\", hue=\"location_state\",marker= 'o', markersize=9)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c17a95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#weighted_avg_margin_by_state.to_csv('flowhub_sales_state_wgt_avg_df_v0.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875a2485",
   "metadata": {},
   "outputs": [],
   "source": [
    "#co.sort_values(by = 'margin_perc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "260f2dec",
   "metadata": {},
   "source": [
    "# Distribution of margin by states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6e9bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966f2e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1e0044",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d90055f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#final_df.to_csv('flowhub_location_analysis.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40265706",
   "metadata": {},
   "outputs": [],
   "source": [
    "# distribution of margin\n",
    "margin_distr = final_df.groupby(['location_state','year_month'])['margin_perc'].describe().reset_index()\n",
    "margin_distr['year_month'] = pd.to_datetime(margin_distr['year_month'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa57790",
   "metadata": {},
   "outputs": [],
   "source": [
    "margin_distr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68dc3218",
   "metadata": {},
   "outputs": [],
   "source": [
    "#margin_distr.to_csv('monthly_margin%_distribution_by_state.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72aa388",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, ax =plt.subplots(1,2)\n",
    "sns.lineplot(data=margin_distr, x=\"year_month\", y=\"min\", hue=\"location_state\",marker= 'o', markersize=9,ax=ax[0])\n",
    "ax[0].legend(loc = 4)\n",
    "ax[0].set_title(\"min\", fontsize=15)\n",
    "ax[0].set_xlabel (\"year month\")\n",
    "ax[0].set_ylabel (\"margin %\")\n",
    "sns.lineplot(data=margin_distr, x=\"year_month\", y=\"max\", hue=\"location_state\",marker= 'o', markersize=9,ax=ax[1])\n",
    "plt.ylim([0.7, 1])\n",
    "ax[1].legend(loc = 4)\n",
    "ax[1].set_title(\"max\", fontsize=15)\n",
    "ax[1].set_xlabel (\"year month\")\n",
    "ax[1].set_ylabel (\"margin %\")\n",
    "sns.set(rc={'figure.figsize':(20,6)})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf8fcbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax =plt.subplots(1,2)\n",
    "sns.lineplot(data=margin_distr, x=\"year_month\", y=\"mean\", hue=\"location_state\",marker= 'o', markersize=9,ax=ax[0])\n",
    "ax[0].set(ylim=(0.7, 1))\n",
    "ax[0].set_title(\"mean\", fontsize=15)\n",
    "ax[0].set_xlabel (\"year month\")\n",
    "ax[0].set_ylabel (\"margin %\")\n",
    "sns.lineplot(data=margin_distr, x=\"year_month\", y=\"50%\", hue=\"location_state\",marker= 'o', markersize=9,ax=ax[1])\n",
    "ax[1].set(ylim=(0.7, 1))\n",
    "ax[1].set_title(\"median\", fontsize=15)\n",
    "ax[1].set_xlabel (\"year month\")\n",
    "ax[1].set_ylabel (\"margin %\")\n",
    "sns.set(rc={'figure.figsize':(20,6)})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0b3978",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax =plt.subplots(1,2)\n",
    "sns.lineplot(data=margin_distr, x=\"year_month\", y=\"25%\", hue=\"location_state\",marker= 'o', markersize=9,ax=ax[0])\n",
    "ax[0].set(ylim=(0.6, 1))\n",
    "ax[0].set_title(\"25th\", fontsize=15)\n",
    "ax[0].set_xlabel (\"year month\")\n",
    "ax[0].set_ylabel (\"margin %\")\n",
    "sns.lineplot(data=margin_distr, x=\"year_month\", y=\"75%\", hue=\"location_state\",marker= 'o', markersize=9,ax=ax[1])\n",
    "ax[1].set(ylim=(0.6, 1))\n",
    "ax[1].set_title(\"75th\", fontsize=15)\n",
    "ax[1].set_xlabel (\"year month\")\n",
    "ax[1].set_ylabel (\"margin %\")\n",
    "sns.set(rc={'figure.figsize':(20,6)})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4dd7a4c",
   "metadata": {},
   "source": [
    "# Distribution of revenue by states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95153504",
   "metadata": {},
   "outputs": [],
   "source": [
    "# distribution of revenue\n",
    "revenue_distr = final_df.groupby(['location_state','year_month'])['NetSales'].describe().reset_index()\n",
    "revenue_distr['year_month'] = pd.to_datetime(revenue_distr['year_month'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f93b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "revenue_distr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8bcccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, ax =plt.subplots(1,2)\n",
    "sns.lineplot(data=revenue_distr, x=\"year_month\", y=\"min\", hue=\"location_state\",marker= 'o', markersize=9,ax=ax[0])\n",
    "ax[0].legend(loc = 4)\n",
    "ax[0].set_title(\"min\", fontsize=15)\n",
    "ax[0].set_xlabel (\"year month\")\n",
    "ax[0].set_ylabel (\"margin %\")\n",
    "sns.lineplot(data=revenue_distr, x=\"year_month\", y=\"max\", hue=\"location_state\",marker= 'o', markersize=9,ax=ax[1])\n",
    "ax[1].legend(loc = 4)\n",
    "ax[1].set_title(\"max\", fontsize=15)\n",
    "ax[1].set_xlabel (\"year month\")\n",
    "ax[1].set_ylabel (\"margin %\")\n",
    "sns.set(rc={'figure.figsize':(20,6)})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c14ba8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax =plt.subplots(1,2)\n",
    "sns.lineplot(data=revenue_distr, x=\"year_month\", y=\"mean\", hue=\"location_state\",marker= 'o', markersize=9,ax=ax[0])\n",
    "#ax[0].set(ylim=(0.7, 1))\n",
    "ax[0].set_title(\"mean\", fontsize=15)\n",
    "ax[0].set_xlabel (\"year month\")\n",
    "ax[0].set_ylabel (\"margin %\")\n",
    "sns.lineplot(data=revenue_distr, x=\"year_month\", y=\"50%\", hue=\"location_state\",marker= 'o', markersize=9,ax=ax[1])\n",
    "#ax[1].set(ylim=(0.7, 1))\n",
    "ax[1].set_title(\"median\", fontsize=15)\n",
    "ax[1].set_xlabel (\"year month\")\n",
    "ax[1].set_ylabel (\"margin %\")\n",
    "sns.set(rc={'figure.figsize':(20,6)})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1fc61e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax =plt.subplots(1,2)\n",
    "sns.lineplot(data=revenue_distr, x=\"year_month\", y=\"25%\", hue=\"location_state\",marker= 'o', markersize=9,ax=ax[0])\n",
    "#ax[0].set(ylim=(0.6, 1))\n",
    "ax[0].set_title(\"25%\", fontsize=15)\n",
    "ax[0].set_xlabel (\"year month\")\n",
    "ax[0].set_ylabel (\"margin %\")\n",
    "sns.lineplot(data=revenue_distr, x=\"year_month\", y=\"75%\", hue=\"location_state\",marker= 'o', markersize=9,ax=ax[1])\n",
    "#ax[1].set(ylim=(0.6, 1))\n",
    "ax[1].set_title(\"75%\", fontsize=15)\n",
    "ax[1].set_xlabel (\"year month\")\n",
    "ax[1].set_ylabel (\"margin %\")\n",
    "sns.set(rc={'figure.figsize':(20,6)})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e20569",
   "metadata": {},
   "outputs": [],
   "source": [
    "#revenue_distr.to_csv('monthly_revenue_distribution_by_state.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53b0933",
   "metadata": {},
   "source": [
    "# by product category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299930b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f6fa90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process_df_by_cat(df,loc_id,loc_state):\n",
    "    df = (\n",
    "        df\n",
    "        .assign(**{\"SalesCreatedAt\": lambda df_: pd.to_datetime(df_['SalesCreatedAt'])})\n",
    "        .assign(**{\"year_month\": lambda df_: df_['SalesCreatedAt'].dt.strftime('%Y-%m')})\n",
    "        .replace('None', np.nan).fillna(0)\n",
    "    )\n",
    "    #exclude cost < $1.0\n",
    "    df_low_cost = df[df['costInDollars'] < 1.0]\n",
    "    df_non_low_cost = df[df['costInDollars'] >= 1.0]\n",
    "    perc_low_cost = df_low_cost.shape[0] / df.shape[0]\n",
    "    #exclude category = Accessory\n",
    "    df_accessory = df_non_low_cost[df_non_low_cost['category'] == 'Accessory']\n",
    "    df_non_accessory = df_non_low_cost[df_non_low_cost['category'] != 'Accessory']\n",
    "    perc_accessory = df_accessory.shape[0] / df.shape[0]\n",
    "    # cogs\n",
    "    cogs = df_non_accessory[['year_month','category','NetSales','costInDollars']].groupby(['year_month','category']).sum()\n",
    "    cogs['profit'] = cogs['NetSales'] - cogs['costInDollars']\n",
    "    cogs['margin_perc'] = cogs['profit'] / cogs['NetSales']\n",
    "    cogs['location_id'] = loc_id\n",
    "    cogs['location_state'] = loc_state\n",
    "    return cogs.reset_index(),perc_low_cost,perc_accessory\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264a01fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_cat = []\n",
    "\n",
    "for company_id, location_id, location_state, df in tqdm(company_location_dataframes):\n",
    "    if len(df) == 0:\n",
    "        continue\n",
    "    res_cat.append(pre_process_df_by_cat(df, location_id, location_state)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db34c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df_cat = pd.concat(res_cat).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f1d6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_margin_distr = final_df_cat.groupby(['category','year_month'])['margin_perc'].describe().reset_index()\n",
    "cat_margin_distr['year_month'] = pd.to_datetime(cat_margin_distr['year_month'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a526beba",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_margin_distr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cbc2d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize':(20,9)})\n",
    "palette = sns.color_palette(\"cubehelix\",15)\n",
    "sns.lineplot(data=cat_margin_distr, x=\"year_month\", y=\"50%\", hue=\"category\",marker= 'o', markersize=9,palette=palette)\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5a3e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_by_state = final_df_cat[['location_state','category','margin_perc']].groupby(['location_state','category']).median().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8cc5add",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize':(12,10)})\n",
    "palette = sns.color_palette(\"Paired_r\",15)\n",
    "ax = sns.barplot(x=\"margin_perc\", y=\"location_state\", hue=\"category\", data=cat_by_state,palette=palette)\n",
    "ax.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "ax.set_xlabel (\"median margin %\")\n",
    "ax.set_ylabel (\"location state\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a9619c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_by_state[cat_by_state['location_state'] == 'CA'].sort_values(by = 'margin_perc', ascending = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
