{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f491e0db-b6d6-480c-be42-5b1e16ddb1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "  A manager that facilitates reading and writing files to GCP Storage\n",
    "\"\"\"\n",
    "import logging\n",
    "import os\n",
    "import subprocess\n",
    "from io import BytesIO\n",
    "from typing import List, Dict, Callable, Tuple, Union\n",
    "from mypy_extensions import TypedDict\n",
    "\n",
    "from google.cloud import storage # type: ignore\n",
    "\n",
    "def get_path_prefix(root_dir: str, relative_path: str) -> str:\n",
    "    prefix = ''\n",
    "    if root_dir:\n",
    "        prefix = root_dir.rstrip('/') + '/'\n",
    "\n",
    "    if relative_path and relative_path != '/':\n",
    "        prefix = prefix + relative_path.strip('/') + '/'\n",
    "\n",
    "    return prefix\n",
    "\n",
    "class PathNode(TypedDict, total=False):\n",
    "    name: str\n",
    "    type: str\n",
    "    size: float\n",
    "        \n",
    "class GCPStorageManager(object):\n",
    "\n",
    "    def __init__(self, storage_details: Dict, verbose: bool) -> None:\n",
    "        self._bucket_name = storage_details.get('bucket')\n",
    "        self._root_dir = storage_details.get('root')\n",
    "        self.client = storage.Client()\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def _abs_path(self, rel_path: str) -> str:\n",
    "        if not self._root_dir:\n",
    "            return rel_path\n",
    "\n",
    "        return os.path.join(self._root_dir, rel_path)\n",
    "\n",
    "    def _build_current_url(self) -> str:\n",
    "        if self._root_dir:\n",
    "            return \"https://console.cloud.google.com/storage/browser/\" + self._bucket_name + \"/\" + self._root_dir\n",
    "        else:\n",
    "            return \"https://console.cloud.google.com/storage/browser/\" + self._bucket_name\n",
    "\n",
    "    def get_root_dir(self) -> str:\n",
    "        return self._root_dir\n",
    "\n",
    "    def get_storage_details(self) -> Dict:\n",
    "        return {\n",
    "            'provider': file_utils.ProviderList.GCP_STORAGE,\n",
    "            'bucket': self._bucket_name,\n",
    "            'root': self._root_dir\n",
    "        }\n",
    "\n",
    "    def get_sync_login_command(self, env_vars: Dict) -> List[str]:\n",
    "        return None\n",
    "\n",
    "    def get_sync_url(self, path: str) -> str:\n",
    "        if not path or path == '/':\n",
    "            abs_path = self._root_dir\n",
    "        else:\n",
    "            abs_path = self._abs_path(path)\n",
    "        return f'gs://{self._bucket_name}/{abs_path}'\n",
    "\n",
    "    def get_sync_command(self, src_dir: str, remote_path: str) -> Callable:\n",
    "\n",
    "        def sync_call() -> Tuple[int, str]:\n",
    "            cmd = ['gsutil', 'rsync', '-r', src_dir, self.get_sync_url(remote_path)]\n",
    "            p = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "            stdout, stderr = p.communicate()\n",
    "            err_code = 0\n",
    "            stderr_val = ''\n",
    "\n",
    "            if p.returncode != 0:\n",
    "                logging.error('Copy response is: {}'.format(stderr.decode('utf-8')))\n",
    "                stderr_val = stderr.decode('utf-8')\n",
    "                err_code = p.returncode\n",
    "\n",
    "            return err_code, stderr_val\n",
    "\n",
    "        return sync_call\n",
    "\n",
    "    def rm_file(self, relative_path: str) -> None:\n",
    "        bucket = self.client.bucket(self._bucket_name)\n",
    "        path = self._abs_path(relative_path)\n",
    "        blob = bucket.blob(path)\n",
    "        logging.info('Deleting file at ' + path)\n",
    "        blob.delete()\n",
    "\n",
    "    def rm_dir(self, relative_path: str) -> None:\n",
    "        bucket = self.client.bucket(self._bucket_name)\n",
    "        prefix = get_path_prefix(self._root_dir, relative_path)\n",
    "        blob = bucket.blob(prefix)\n",
    "        logging.info('Deleting files at ' + prefix)\n",
    "        blob.delete()\n",
    "\n",
    "    def read_content(self, path: str, throw_exception: bool, read_range: str = None, streaming: bool = False) -> bytes:\n",
    "        try:\n",
    "            path = self._abs_path(path)\n",
    "            bucket = self.client.bucket(self._bucket_name)\n",
    "            blob = bucket.blob(path)\n",
    "            result = blob.download_as_bytes()\n",
    "\n",
    "            if self.verbose:\n",
    "                logging.info(f\"Downloading content from {self._build_current_url()}/{path}\")\n",
    "\n",
    "            return result\n",
    "        except Exception as e:\n",
    "            raise\n",
    "\n",
    "    #def gen_presigned_url(self, path: str) -> str:\n",
    "    #    # dask and other frameworks explicit s3 link rather than a byte stream or contet (e.g. s3://bucket/foo.csv)\n",
    "    #    return self._s3.generate_presigned_url('get_object',\n",
    "    #                                           Params={'Bucket': self._bucket_name, 'Key': self._abs_path(path)})\n",
    "\n",
    "    # Checks to see if the job directory exists.  No side-effects.\n",
    "    def check_dir_exists(self, path: str) -> bool:\n",
    "        # Create the prefix for this particular job.\n",
    "        exists = False\n",
    "        prefix = get_path_prefix(self._root_dir, path)\n",
    "        blobs = list(self.client.list_blobs(\n",
    "            self._bucket_name, prefix=prefix\n",
    "        ))\n",
    "        if len(blobs) > 0:\n",
    "            exists = True\n",
    "\n",
    "        return exists\n",
    "\n",
    "    def _download_content(self, remote_path: str) -> bytes:\n",
    "        remote_path = self._abs_path(remote_path)\n",
    "        bucket = self.client.bucket(self._bucket_name)\n",
    "        blob = bucket.blob(remote_path)\n",
    "        if self.verbose:\n",
    "            logging.info(f\"Downloading content from {self._build_current_url()}/{remote_path}\")\n",
    "\n",
    "        fileobj = BytesIO()\n",
    "        blob.download_to_file(fileobj)\n",
    "        return fileobj.getvalue()\n",
    "\n",
    "    def download_file(self, remote_path: str, file_name: str) -> None:\n",
    "        # Move references to large data items across folders\n",
    "        remote_path = self._abs_path(remote_path)\n",
    "        bucket = self.client.bucket(self._bucket_name)\n",
    "        blob = bucket.blob(remote_path)\n",
    "        if self.verbose:\n",
    "            logging.info(f\"Downloading file {self._build_current_url()}/{remote_path} to {file_name}\")\n",
    "\n",
    "        dirname = os.path.dirname(file_name)\n",
    "\n",
    "        if dirname:\n",
    "            # Only create a directory if it's not ''\n",
    "            if not os.path.exists(dirname):\n",
    "                os.makedirs(dirname)\n",
    "\n",
    "        blob.download_to_filename(file_name)\n",
    "\n",
    "    def download_and_unzip(self, remote_path: str, local_dir: str) -> None:\n",
    "        zip_bytes = self._download_content(remote_path)\n",
    "        file_utils.unzip_into_dir(zip_bytes, local_dir)\n",
    "\n",
    "    def download_dir(self, remote_path: str, local_path: str) -> int:\n",
    "        nFiles = 0\n",
    "        if self.verbose:\n",
    "            logging.info(\"Downloading folder: \" + remote_path + \" to \" + local_path)\n",
    "\n",
    "        prefix = file_utils.get_path_prefix(self._root_dir, remote_path)\n",
    "        for blob in self.client.list_blobs(self._bucket_name, prefix=prefix):\n",
    "            if blob.name.endswith('/'):\n",
    "                continue\n",
    "\n",
    "            rel_path = os.path.relpath(blob.name, prefix)\n",
    "            dest_pathname = os.path.join(local_path, rel_path)\n",
    "\n",
    "            if not os.path.exists(os.path.dirname(dest_pathname)):\n",
    "                os.makedirs(os.path.dirname(dest_pathname))\n",
    "\n",
    "            if self.verbose:\n",
    "                logging.info(f\"Downloading file {blob.name} to {dest_pathname}\")\n",
    "\n",
    "            blob.download_to_filename(dest_pathname)  # Download\n",
    "            nFiles += 1\n",
    "\n",
    "        return nFiles\n",
    "\n",
    "    def upload_content(self, content: bytes, file_name: str) -> None:\n",
    "        # Uploads file content to a specific filename location\n",
    "        bucket = self.client.bucket(self._bucket_name)\n",
    "        if self.verbose:\n",
    "            logging.info(f\"Uploading content to {self._build_current_url()}/{file_name}\")\n",
    "\n",
    "        blob = bucket.blob(self._abs_path(file_name))\n",
    "        blob.upload_from_file(BytesIO(content))\n",
    "\n",
    "    def list_directory(self, path: str, with_size: bool = False) -> Dict:\n",
    "        prefix = get_path_prefix(self._root_dir, path)\n",
    "        bucket = self.client.bucket(self._bucket_name)\n",
    "        blobs = bucket.list_blobs(prefix=prefix)\n",
    "        nodes = []\n",
    "        for blob in blobs:\n",
    "            if blob.name.endswith('/'):\n",
    "                nodes.append(PathNode(name=os.path.basename(blob.name[:-1]), type='folder'))\n",
    "            else:\n",
    "                nodes.append(PathNode(name=os.path.basename(blob.name), type='file'))\n",
    "\n",
    "        return {\n",
    "            'nodes': nodes\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac19077f-ab85-4246-955d-f00e6e0137a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/warren/sweat-equity-ventures/bespoke/flowhub_gcp_credentials.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(verbose=True)\n",
    "\n",
    "print(os.environ.get('GOOGLE_APPLICATION_CREDENTIALS'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f5d97ba-91e8-41e1-b662-4f97a75810a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "manager = GCPStorageManager({\n",
    "    'bucket': 'partnerships-data-reporting',\n",
    "    'root': ''\n",
    "}, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cbc08e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "if sys.version_info[0] < 3: \n",
    "    from StringIO import StringIO\n",
    "else:\n",
    "    from io import StringIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d515f4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "directory_contents = manager.list_directory('')['nodes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5f1624c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 100 companies in the dataset\n"
     ]
    }
   ],
   "source": [
    "company_ids_set = set([])\n",
    "\n",
    "for file_metadata in directory_contents:\n",
    "    file_name = file_metadata['name']\n",
    "    # Company locations file case.\n",
    "    if '_locations.csv' in file_name:\n",
    "        company_id = file_name.replace('_locations.csv', '')\n",
    "        company_ids_set.add(company_id)\n",
    "\n",
    "company_ids_count = len(list(company_ids_set))\n",
    "print(f'There are {company_ids_count} companies in the dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "037dda03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 178 company locations in the dataset\n"
     ]
    }
   ],
   "source": [
    "company_location_ids_set = set([])\n",
    "\n",
    "for company_id in company_ids_set:\n",
    "    locations_csv_string = manager.read_content(f'{company_id}/{company_id}_locations.csv', throw_exception=True)\n",
    "    locations_io = StringIO(locations_csv_string.decode(\"utf-8\"))\n",
    "    locations_dataframe = pd.read_csv(locations_io)\n",
    "    location_ids = locations_dataframe['locationId'].tolist()\n",
    "    for location_id in location_ids:\n",
    "        company_location_ids_set.add((company_id, location_id))\n",
    "\n",
    "company_location_ids_count = len(list(company_location_ids_set))\n",
    "print(f'There are {company_location_ids_count} company locations in the dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "14f3e8e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] Downloading sales dataframe for location (pTYqYSwRCuxLKKzME, QQvD4yk7CAtH2MDwa)\n",
      "[2] Downloading sales dataframe for location (Q2ctDDsxjy23AoQLb, QzxtSrfS8dh3qWsWm)\n",
      "[3] Downloading sales dataframe for location (T3nGGs9v9BkBJkLAJ, TpetsriCnhipdAvdb)\n",
      "[4] Downloading sales dataframe for location (SPYsqAwk5XEjp9ZwX, wvkqmogsjjjfSSocY)\n",
      "[5] Downloading sales dataframe for location (rPXmTTcY4LXmgmTcG, PYKgsLK9FTwcSnmaT)\n",
      "[6] Downloading sales dataframe for location (6YRM2orTfSySDKhLL, R5EZkhoLBF9e7qxmF)\n",
      "[7] Downloading sales dataframe for location (E2ZWysfDHW2pqB7JW, icLHyCEKBqp4b4sGK)\n",
      "[8] Downloading sales dataframe for location (dJg8Bmr3FDZhipSJe, rZCY6mc4x8y7Fepu6)\n",
      "[9] Downloading sales dataframe for location (j7MWhCyfRAgZstQdE, WPz3hFKPNePY6kFyT)\n",
      "[10] Downloading sales dataframe for location (GNPWTqYqZsfcAA6Jb, tjPZFyNwNnYMc8jcE)\n",
      "[11] Downloading sales dataframe for location (KkyhzzHqgJDFWPM9n, Ceoy5YkSujnhNt5Zn)\n",
      "[12] Downloading sales dataframe for location (9jrcBWKRkf9wgQ6mr, 6EAiLXwCs9wfXHbgG)\n",
      "[13] Downloading sales dataframe for location (ySB2RKAtEDYKERK9J, 2t3guxpfanCWqycA6)\n",
      "[14] Downloading sales dataframe for location (hPzYzThkKMuQrF9Q2, zKiH8jXK5S7cw5j5N)\n",
      "[15] Downloading sales dataframe for location (KkyhzzHqgJDFWPM9n, muYwpddLcAc6gTYYS)\n",
      "[16] Downloading sales dataframe for location (FhSceFrGthqNntkEE, nkTZx6zDkxzBitF2D)\n",
      "[17] Downloading sales dataframe for location (rgNDsz626CTLnd53Y, HJho8PdduZazwxzet)\n",
      "[18] Downloading sales dataframe for location (iJscrRfw6uYjEhEKo, m4qw2bLpeNRpkwSog)\n",
      "[19] Downloading sales dataframe for location (wiyY5tNikq6WRPQ6E, q5ibpyhJiEuBwYCJv)\n",
      "[20] Downloading sales dataframe for location (iJscrRfw6uYjEhEKo, KrCPtJaQmpa3cjXXN)\n",
      "[21] Downloading sales dataframe for location (KypyS8kNFhSPZxv7q, w2nkNYHgjfaWNPiCZ)\n",
      "[22] Downloading sales dataframe for location (7R5MBJ2wAH328M9P7, YmCZQD9MS5SLdc3AF)\n",
      "[23] Downloading sales dataframe for location (PhGThGEkoJR7xy64q, j5Z3K6oX85m5xbH2T)\n",
      "[24] Downloading sales dataframe for location (KypyS8kNFhSPZxv7q, GG4cRK5ci6BnXXrek)\n",
      "[25] Downloading sales dataframe for location (7yxgKNbqd5PMNzX3P, nkd4rFdkFuwkzREqM)\n",
      "[26] Downloading sales dataframe for location (6DwQ3xhCWDGBRFFss, xiJBqHKLRED7J2vHe)\n",
      "[27] Downloading sales dataframe for location (rPXmTTcY4LXmgmTcG, Wn3vq5TEvzEjrLoeo)\n",
      "[28] Downloading sales dataframe for location (dPBnHGGKDN7BoewSb, k5QDGuijL8LfzKWbT)\n",
      "[29] Downloading sales dataframe for location (df3sSmAoAmLuSmJWq, p6oXYdLQq99TZAHAw)\n",
      "[30] Downloading sales dataframe for location (4xWeGuAg4jDmZSWxA, b5KEZ723yYvGdccgv)\n",
      "[31] Downloading sales dataframe for location (7yxgKNbqd5PMNzX3P, pDTpb5jcBPCkaM9Y4)\n",
      "[32] Downloading sales dataframe for location (8fkcBjcmScuidkvn2, uf4FdoqBp8jKtAsGg)\n",
      "[32] An exception occurred for location (8fkcBjcmScuidkvn2, uf4FdoqBp8jKtAsGg)\n",
      "[33] Downloading sales dataframe for location (9aGAdAw3tYQ4MxCBc, eXX2KbkJinAoMSMJ8)\n",
      "[34] Downloading sales dataframe for location (fEsQ8GsoDAnE7KesF, LzgZfrLTtusirBknS)\n",
      "[35] Downloading sales dataframe for location (ueTXJNrihTPQS97vZ, Hcug7wxTBbgdcwuBp)\n",
      "[36] Downloading sales dataframe for location (P63pMT9HvTtdmhWcL, wceNMPjZukYhbKu4q)\n",
      "[37] Downloading sales dataframe for location (zYJtFZdBBkQscrfpN, WSWKMiXdHM7Pjuk2E)\n",
      "[38] Downloading sales dataframe for location (rgNDsz626CTLnd53Y, K5Toc7ZAJCFQ9e45G)\n",
      "[39] Downloading sales dataframe for location (D4whhBS6cDZcxZTWQ, SbXJngA5SJw6fX4X7)\n",
      "[40] Downloading sales dataframe for location (o46tyNKeC4xHZeh7h, kc7H5MybfG8z4QuAB)\n",
      "[41] Downloading sales dataframe for location (ByCLyAjbSNLZFD4pc, oT9Y9S9wG9xzkCqTH)\n",
      "[42] Downloading sales dataframe for location (P63pMT9HvTtdmhWcL, w6GrPdpwkjbsweeKC)\n",
      "[43] Downloading sales dataframe for location (cJzxLPbsT2xWzayjT, 5WjAeATyNJQEBp2Jp)\n",
      "[44] Downloading sales dataframe for location (P63pMT9HvTtdmhWcL, iqfzKWKpcHmcw3zyB)\n",
      "[45] Downloading sales dataframe for location (KkyhzzHqgJDFWPM9n, boeYRjqKsN58hCttJ)\n",
      "[46] Downloading sales dataframe for location (JjtbeWp3LdAJp4xME, d8D9R65o75dzizwv7)\n",
      "[47] Downloading sales dataframe for location (9aGAdAw3tYQ4MxCBc, mBaukdLE4GfLJHMk3)\n",
      "[48] Downloading sales dataframe for location (caH9RMynqjrmihrxA, SMxaDCwvRkk9W5CYo)\n",
      "[49] Downloading sales dataframe for location (rgNDsz626CTLnd53Y, vcSWQf42MRtpLdAyH)\n",
      "[50] Downloading sales dataframe for location (6DwQ3xhCWDGBRFFss, bS7R8w9hgETJuiZoj)\n",
      "[51] Downloading sales dataframe for location (X28YzezeSoJRkQG5k, nkezQjPpvGv3imnQC)\n",
      "[52] Downloading sales dataframe for location (6DwQ3xhCWDGBRFFss, YLEEhTz7umoffAPqd)\n",
      "[53] Downloading sales dataframe for location (P63pMT9HvTtdmhWcL, 6MixYQuZj8dX3wZaH)\n",
      "[54] Downloading sales dataframe for location (L7ME43C6TAoYv6HCb, 4hmkTc8KYoncMnH59)\n",
      "[55] Downloading sales dataframe for location (dPBnHGGKDN7BoewSb, Pm6LiFkoePFdAKSaL)\n",
      "[56] Downloading sales dataframe for location (XvKkyKyMz4g2D7jr3, rJPS4snkZyiazJ5ba)\n",
      "[57] Downloading sales dataframe for location (7yxgKNbqd5PMNzX3P, TdyAhrZWq6MDeyNvu)\n",
      "[58] Downloading sales dataframe for location (j7MWhCyfRAgZstQdE, BcggJ8dJgf6dG4HD6)\n",
      "[59] Downloading sales dataframe for location (dPBnHGGKDN7BoewSb, JTYN5fzmttm5Hp2nu)\n",
      "[60] Downloading sales dataframe for location (rgNDsz626CTLnd53Y, a99L3qQLhzu2mjmCT)\n",
      "[61] Downloading sales dataframe for location (AqJKG5gJ7MFSeX2Rp, txeeYRyjoA8XKgudG)\n",
      "[62] Downloading sales dataframe for location (soGf2Qcrw8hz3zw7A, hJnyq4aQmJ8ZPDN2p)\n",
      "[63] Downloading sales dataframe for location (W9FX7xfES6pZPg4o8, hoL6QWpKg4mFEEiB2)\n",
      "[64] Downloading sales dataframe for location (WCoDEv4fPzofmrowz, F83aT7SK4wCj9pGMR)\n",
      "[65] Downloading sales dataframe for location (hcLfFhKstdmNNtBjx, stEZcHzK7YnStjxEY)\n",
      "[66] Downloading sales dataframe for location (s4fnrie58B29225jc, bhKv2q34nZ3pwig9G)\n",
      "[67] Downloading sales dataframe for location (iyMFa4iWBQcwDJ96J, 7d2n9JxXJASYWzxxm)\n",
      "[68] Downloading sales dataframe for location (Q2ctDDsxjy23AoQLb, 2yBx7nstyQ8ZsAmJr)\n",
      "[69] Downloading sales dataframe for location (9RfzKgXJn46NXH4Lm, HiupCL6yiRpbhdTWC)\n",
      "[70] Downloading sales dataframe for location (KypyS8kNFhSPZxv7q, ofeoiXgSPuM6PCyaN)\n",
      "[71] Downloading sales dataframe for location (YYejGWetywzcxRhn6, 3KTQcT9Stpofdf5kB)\n",
      "[72] Downloading sales dataframe for location (EeKxS92bT8BmGsavE, GR8ucGDAawJ8XkF94)\n",
      "[73] Downloading sales dataframe for location (Q2ctDDsxjy23AoQLb, Q2kMvxBHw5BF4acj3)\n",
      "[74] Downloading sales dataframe for location (Q2ctDDsxjy23AoQLb, qxiz5WYXaraD6m9cw)\n",
      "[75] Downloading sales dataframe for location (skr37kBKma2BsYjxM, prYYNAY7hcMLYJzd9)\n",
      "[76] Downloading sales dataframe for location (XQak5YK9eZfXYhKgJ, wFgewqSvmGEQzyrLQ)\n",
      "[77] Downloading sales dataframe for location (HmNDEqWf2NvmYGpZu, ZRSc2RYzna9Kni6Lo)\n",
      "[78] Downloading sales dataframe for location (s4fnrie58B29225jc, wBbhHYEDp52BowBXg)\n",
      "[79] Downloading sales dataframe for location (hPzYzThkKMuQrF9Q2, kWheTth4u6uMC4CC9)\n",
      "[80] Downloading sales dataframe for location (iJscrRfw6uYjEhEKo, YzMPTXGLr6SqEDAWY)\n",
      "[81] Downloading sales dataframe for location (8fkcBjcmScuidkvn2, MuirNe829ZExjNmek)\n",
      "[82] Downloading sales dataframe for location (cSuhZSQExaug3odn5, iksYoAeKHCziH8wjb)\n",
      "[83] Downloading sales dataframe for location (FeYB32454Az4yNvon, RFBbCqSpf2vmTqWfS)\n",
      "[84] Downloading sales dataframe for location (7SRQ7Z7xuN5EGXGSu, hTZZG34NPtdCXgXvf)\n",
      "[85] Downloading sales dataframe for location (H7LmfTFQfqAqxaeGf, LPLszRsYMomFaBAQR)\n",
      "[86] Downloading sales dataframe for location (gmAmheWQLfWvhg7aF, p5YBJDMCPA7PcwEDA)\n",
      "[87] Downloading sales dataframe for location (XQak5YK9eZfXYhKgJ, 4AnrvwyLnHh4YXT7k)\n",
      "[88] Downloading sales dataframe for location (6K9bzPik9WxNFCceT, nMdvN7zKuFLBwkye7)\n",
      "[89] Downloading sales dataframe for location (iyMFa4iWBQcwDJ96J, c8tpERbSmkRvaauEn)\n",
      "[90] Downloading sales dataframe for location (gMn8iLck9MHoDu2xn, NCCNyEZrTpaHmptK6)\n",
      "[91] Downloading sales dataframe for location (7SRQ7Z7xuN5EGXGSu, JDcPyy6NfkQHkyK5C)\n",
      "[92] Downloading sales dataframe for location (uBkpbfZHy55ndgnTv, JL5zpyFxo7J3rHxZK)\n",
      "[93] Downloading sales dataframe for location (dPBnHGGKDN7BoewSb, noh5XdbxTK5gRSLMt)\n",
      "[94] Downloading sales dataframe for location (jfD4EGaLur6xsEHbQ, 9qbx82jZwxnvdDDNX)\n",
      "[95] Downloading sales dataframe for location (my6fhmSxAxbdFvBKm, Ttf4XqarkihAm2Fen)\n",
      "[96] Downloading sales dataframe for location (soGf2Qcrw8hz3zw7A, hWwpRPYtQk9D9ub8S)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[97] Downloading sales dataframe for location (rgNDsz626CTLnd53Y, NsTkwrKuNqSPpjxJn)\n",
      "[98] Downloading sales dataframe for location (exFwNR5F4o5DGDKRW, AmkkHfRm6RjhEJGrK)\n",
      "[99] Downloading sales dataframe for location (j7MWhCyfRAgZstQdE, Xa54Pov4FpuTxizDd)\n",
      "[100] Downloading sales dataframe for location (D2JsangYtSFya4nDT, G4yyguo4R7wGp3NR8)\n",
      "[101] Downloading sales dataframe for location (QtFmR4Qgdk2fcYQ2h, p4uoisdtyfqeYk4GX)\n",
      "[102] Downloading sales dataframe for location (jfD4EGaLur6xsEHbQ, Wjgbcenow3oSALsgJ)\n",
      "[103] Downloading sales dataframe for location (E2ZWysfDHW2pqB7JW, aYt5FfpYq2GnTagfC)\n",
      "[104] Downloading sales dataframe for location (kEYekxChnHJ5FRAc4, pwJ65xWrRyZ4QFJGP)\n",
      "[105] Downloading sales dataframe for location (FuDLDjBXzkEPPQxZD, TgLFQQcK4NiY8unCE)\n",
      "[106] Downloading sales dataframe for location (KypyS8kNFhSPZxv7q, RJxDzpLGARNoej3x9)\n",
      "[107] Downloading sales dataframe for location (rrCXhvarvXo7P2fGo, g63EjGYZsjHPqyPL4)\n",
      "[108] Downloading sales dataframe for location (QZaMHjsdRoCrM6YpT, fNwQTfW3g6RHFzem2)\n",
      "[109] Downloading sales dataframe for location (kEYekxChnHJ5FRAc4, yTKh8QP9Yk7aQc7E3)\n",
      "[110] Downloading sales dataframe for location (dJg8Bmr3FDZhipSJe, 43HM2Zu77qrMksWB8)\n",
      "[111] Downloading sales dataframe for location (jHRWDbw2acLnecEMb, Apjz33PejC6nxM44Q)\n",
      "[112] Downloading sales dataframe for location (kKBqnAwywSrKLGQpk, qMqFJoMnwH5fYqfzc)\n",
      "[113] Downloading sales dataframe for location (NdvsZACyTb6HHHz5e, GmRxcxhgYYbY4rzWt)\n",
      "[114] Downloading sales dataframe for location (hcLfFhKstdmNNtBjx, WCXL3HhQzSr6kHaAX)\n",
      "[115] Downloading sales dataframe for location (7SRQ7Z7xuN5EGXGSu, SrS9ay3mNoQzJ79ys)\n",
      "[116] Downloading sales dataframe for location (rgNDsz626CTLnd53Y, wGDNyMATiZMDwrEAC)\n",
      "[117] Downloading sales dataframe for location (TETLayDXwuGSrkANd, Prey6qWiR9qx42BfZ)\n",
      "[118] Downloading sales dataframe for location (4A5DE8Zj5gDtSmCbn, JYAZRDbztXRLwJ5r6)\n",
      "[119] Downloading sales dataframe for location (E64uo3RvNGNDpvzsD, sLxB8GHBxW96yLLEc)\n",
      "[120] Downloading sales dataframe for location (jfD4EGaLur6xsEHbQ, dRuDEyZkyY4YsToMD)\n",
      "[121] Downloading sales dataframe for location (dPBnHGGKDN7BoewSb, GquEcaJjTtznA2SNW)\n",
      "[122] Downloading sales dataframe for location (soGf2Qcrw8hz3zw7A, Fk7nnkg6WfWqTbA6r)\n",
      "[123] Downloading sales dataframe for location (E2ZWysfDHW2pqB7JW, B8pM9KEBveyEBEN34)\n",
      "[124] Downloading sales dataframe for location (s4fnrie58B29225jc, Qzo8oZNzMzx2jL6sd)\n",
      "[125] Downloading sales dataframe for location (pTYqYSwRCuxLKKzME, vWcpWc8k7eErZit6B)\n",
      "[126] Downloading sales dataframe for location (dbhjfjAkBf2xnrPDK, NYG4r9zcLLg8dpuDT)\n",
      "[127] Downloading sales dataframe for location (rgNDsz626CTLnd53Y, FiY6sP2fB5xgpo6W7)\n",
      "[128] Downloading sales dataframe for location (Q2ctDDsxjy23AoQLb, PRvKKPwhXmGoDXZeb)\n",
      "[129] Downloading sales dataframe for location (cSnsbv7ccTEXcHAbW, ssbs4evELKRzGP7Mg)\n",
      "[130] Downloading sales dataframe for location (nCruygGQCoYecWbiA, hckksdjCgJZxCoSYx)\n",
      "[131] Downloading sales dataframe for location (SPYsqAwk5XEjp9ZwX, CtuShNA5sgy8GnxMf)\n",
      "[132] Downloading sales dataframe for location (E2ZWysfDHW2pqB7JW, MbmydJAHsgpqFJJ4m)\n",
      "[133] Downloading sales dataframe for location (iJscrRfw6uYjEhEKo, LFjsRXJPgxtXfFzxm)\n",
      "[134] Downloading sales dataframe for location (RqokibKjt6ueZK52s, 4QHc4Kakc8PD8EJR8)\n",
      "[135] Downloading sales dataframe for location (Q2ctDDsxjy23AoQLb, vho4fBSgkDjiGBgup)\n",
      "[136] Downloading sales dataframe for location (dPBnHGGKDN7BoewSb, bqKHM2aszQqLotXYD)\n",
      "[137] Downloading sales dataframe for location (wAcmr4LCaqm2w6LPx, JzSkgYKPM4oTacbbF)\n",
      "[138] Downloading sales dataframe for location (7Grxab9AL8HbnNcCn, J4qscTeHW28gWBxju)\n",
      "[139] Downloading sales dataframe for location (QeJpvdukLbF2jp29u, MChwYqG2LnkKmdY55)\n",
      "[140] Downloading sales dataframe for location (P63pMT9HvTtdmhWcL, A9ZGNP4jxJfp8cErn)\n",
      "[141] Downloading sales dataframe for location (NpqM32uwNRKTTWTb6, hEDskKfvoCGHTkeDp)\n",
      "[142] Downloading sales dataframe for location (d2Q3Ga3jxiBpsHdHe, mE6ABrbzCLjFDRiCK)\n",
      "[143] Downloading sales dataframe for location (pJRQ5CqncC9xk8bdy, bmJuhcYDiqAcbj6Ze)\n",
      "[144] Downloading sales dataframe for location (dPBnHGGKDN7BoewSb, 4H7u5h3YpH7AfhpRh)\n",
      "[145] Downloading sales dataframe for location (KkyhzzHqgJDFWPM9n, 4syN56cW3Mz4jFb9b)\n",
      "[146] Downloading sales dataframe for location (B9GQKa7DehxaHMtSX, REZC5uHgzDKsSqNGB)\n",
      "[147] Downloading sales dataframe for location (KkyhzzHqgJDFWPM9n, EuD42c5biCpsp7YAS)\n",
      "[148] Downloading sales dataframe for location (KkyhzzHqgJDFWPM9n, iSErbHS86nkF2ofqH)\n",
      "[149] Downloading sales dataframe for location (7R5MBJ2wAH328M9P7, kYM3JYW6yPzhuu8tE)\n",
      "[150] Downloading sales dataframe for location (E2ZWysfDHW2pqB7JW, 5CAwD9Rt2kBXddaEC)\n",
      "[151] Downloading sales dataframe for location (rK3atC7axuLcz3iRB, 7M2PxZuR7sPpfgfuJ)\n",
      "[152] Downloading sales dataframe for location (dWLm7ENAouJ4WEoJP, wPF7B3axoELQhodfH)\n",
      "[153] Downloading sales dataframe for location (j7NR2ZFa5vXCAyxzR, ZvfRr674sQivsWR89)\n",
      "[154] Downloading sales dataframe for location (d7u39ZjnznjCCE54L, eYoBctQZTqsmydrHY)\n",
      "[155] Downloading sales dataframe for location (GNPWTqYqZsfcAA6Jb, FgmkhfmA7qPSkMsx4)\n",
      "[156] Downloading sales dataframe for location (rgNDsz626CTLnd53Y, X4umGyWwy8bByo3dp)\n",
      "[157] Downloading sales dataframe for location (ScA2tJQp3iryzrBKS, fDrbnB9KCA2jnDbhg)\n",
      "[158] Downloading sales dataframe for location (6DwQ3xhCWDGBRFFss, CaNMh4HdcNdPFkoYK)\n",
      "[159] Downloading sales dataframe for location (s4fnrie58B29225jc, qh5yT7Q3YFa4RSMvW)\n",
      "[160] Downloading sales dataframe for location (SPYsqAwk5XEjp9ZwX, eLHngApztHXt5s8EM)\n",
      "[161] Downloading sales dataframe for location (E2ZWysfDHW2pqB7JW, EsDe4nRt3MX35cZkb)\n",
      "[162] Downloading sales dataframe for location (QZaMHjsdRoCrM6YpT, HYarvKnCx8LimvPHd)\n",
      "[163] Downloading sales dataframe for location (WFSExqQKtsq6W7At8, H3ZmnEr9cJwLp69KF)\n",
      "[164] Downloading sales dataframe for location (dPBnHGGKDN7BoewSb, wGeAKkDSeYQb22QhS)\n",
      "[165] Downloading sales dataframe for location (P63pMT9HvTtdmhWcL, 8XbpQa8QiwPcuxZbE)\n",
      "[166] Downloading sales dataframe for location (czyNjjNhCHky7mjfu, MDKfxxXkJLGffq9xg)\n",
      "[167] Downloading sales dataframe for location (4xWeGuAg4jDmZSWxA, PY9ucfFTZc4XPSuPC)\n",
      "[168] Downloading sales dataframe for location (E2ZWysfDHW2pqB7JW, 8w9LHWtFkywXHFbjT)\n",
      "[169] Downloading sales dataframe for location (gmAmheWQLfWvhg7aF, rAffv9HziBbzRzqh3)\n",
      "[170] Downloading sales dataframe for location (caH9RMynqjrmihrxA, YWunBwEwPiKPDeiJB)\n",
      "[171] Downloading sales dataframe for location (DwAym344iPb22MYPr, yji6wnh5kT8GZmM26)\n",
      "[172] Downloading sales dataframe for location (JgeRNMvtP3A2tGcEo, aBq33e9dcXdb9JRWR)\n",
      "[173] Downloading sales dataframe for location (ueTXJNrihTPQS97vZ, Procfg9sDkYKKQDAr)\n",
      "[174] Downloading sales dataframe for location (pNvk32k66RwiH4XLW, 35pY3nxKPGdfQKT28)\n",
      "[175] Downloading sales dataframe for location (hbTCMydA4w2TnGqHE, mN2gXpCGvAx4aMbit)\n",
      "[176] Downloading sales dataframe for location (KypyS8kNFhSPZxv7q, hqoDkhKFbRGdjaC9Z)\n",
      "[177] Downloading sales dataframe for location (gmAmheWQLfWvhg7aF, aKiDRWpwJuhLABnWA)\n",
      "[178] Downloading sales dataframe for location (hRXNA7EETb3wW4HSM, buYyQC35TaEXfna9g)\n",
      "There are 177 company location dataframes in the dataset\n"
     ]
    }
   ],
   "source": [
    "# (company_id, location_id, location_sales_dataframe)\n",
    "company_location_dataframes = []\n",
    "\n",
    "for index, company_location_tuple in enumerate(company_location_ids_set):\n",
    "    company_id, company_location_id = company_location_tuple\n",
    "    print(f'[{index + 1}] Downloading sales dataframe for location ({company_id}, {company_location_id})')\n",
    "\n",
    "    try:\n",
    "        location_sales_csv_string = manager.read_content(f'{company_id}/{company_location_id}/{company_location_id}_sales.csv', throw_exception=True)\n",
    "        location_sales_io = StringIO(location_sales_csv_string.decode(\"utf-8\"))\n",
    "        location_sales_dataframe = pd.read_csv(location_sales_io)\n",
    "        company_location_dataframes.append((company_id, company_location_id, location_sales_dataframe))\n",
    "    except:\n",
    "        print(f'[{index + 1}] An exception occurred for location ({company_id}, {company_location_id})')\n",
    "\n",
    "company_location_dataframes_count = len(list(company_location_dataframes))\n",
    "print(f'There are {company_location_dataframes_count} company location dataframes in the dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "121ca3a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pTYqYSwRCuxLKKzME QQvD4yk7CAtH2MDwa (50, 14)\n",
      "Q2ctDDsxjy23AoQLb QzxtSrfS8dh3qWsWm (16478, 14)\n",
      "T3nGGs9v9BkBJkLAJ TpetsriCnhipdAvdb (21752, 14)\n",
      "SPYsqAwk5XEjp9ZwX wvkqmogsjjjfSSocY (126292, 14)\n",
      "rPXmTTcY4LXmgmTcG PYKgsLK9FTwcSnmaT (11445, 14)\n",
      "6YRM2orTfSySDKhLL R5EZkhoLBF9e7qxmF (21429, 14)\n",
      "E2ZWysfDHW2pqB7JW icLHyCEKBqp4b4sGK (38178, 14)\n",
      "dJg8Bmr3FDZhipSJe rZCY6mc4x8y7Fepu6 (99506, 14)\n",
      "j7MWhCyfRAgZstQdE WPz3hFKPNePY6kFyT (1968, 14)\n",
      "GNPWTqYqZsfcAA6Jb tjPZFyNwNnYMc8jcE (55297, 14)\n",
      "KkyhzzHqgJDFWPM9n Ceoy5YkSujnhNt5Zn (0, 14)\n",
      "9jrcBWKRkf9wgQ6mr 6EAiLXwCs9wfXHbgG (86911, 14)\n",
      "ySB2RKAtEDYKERK9J 2t3guxpfanCWqycA6 (26957, 14)\n",
      "hPzYzThkKMuQrF9Q2 zKiH8jXK5S7cw5j5N (16898, 14)\n",
      "KkyhzzHqgJDFWPM9n muYwpddLcAc6gTYYS (0, 14)\n",
      "FhSceFrGthqNntkEE nkTZx6zDkxzBitF2D (253055, 14)\n",
      "rgNDsz626CTLnd53Y HJho8PdduZazwxzet (15942, 14)\n",
      "iJscrRfw6uYjEhEKo m4qw2bLpeNRpkwSog (74041, 14)\n",
      "wiyY5tNikq6WRPQ6E q5ibpyhJiEuBwYCJv (331585, 14)\n",
      "iJscrRfw6uYjEhEKo KrCPtJaQmpa3cjXXN (67631, 14)\n",
      "KypyS8kNFhSPZxv7q w2nkNYHgjfaWNPiCZ (0, 14)\n",
      "7R5MBJ2wAH328M9P7 YmCZQD9MS5SLdc3AF (307368, 14)\n",
      "PhGThGEkoJR7xy64q j5Z3K6oX85m5xbH2T (9554, 14)\n",
      "KypyS8kNFhSPZxv7q GG4cRK5ci6BnXXrek (0, 14)\n",
      "7yxgKNbqd5PMNzX3P nkd4rFdkFuwkzREqM (21928, 14)\n",
      "6DwQ3xhCWDGBRFFss xiJBqHKLRED7J2vHe (0, 14)\n",
      "rPXmTTcY4LXmgmTcG Wn3vq5TEvzEjrLoeo (21157, 14)\n",
      "dPBnHGGKDN7BoewSb k5QDGuijL8LfzKWbT (117099, 14)\n",
      "df3sSmAoAmLuSmJWq p6oXYdLQq99TZAHAw (27106, 14)\n",
      "4xWeGuAg4jDmZSWxA b5KEZ723yYvGdccgv (99510, 14)\n",
      "7yxgKNbqd5PMNzX3P pDTpb5jcBPCkaM9Y4 (142045, 14)\n",
      "9aGAdAw3tYQ4MxCBc eXX2KbkJinAoMSMJ8 (14071, 14)\n",
      "fEsQ8GsoDAnE7KesF LzgZfrLTtusirBknS (39744, 14)\n",
      "ueTXJNrihTPQS97vZ Hcug7wxTBbgdcwuBp (15115, 14)\n",
      "P63pMT9HvTtdmhWcL wceNMPjZukYhbKu4q (161421, 14)\n",
      "zYJtFZdBBkQscrfpN WSWKMiXdHM7Pjuk2E (13657, 14)\n",
      "rgNDsz626CTLnd53Y K5Toc7ZAJCFQ9e45G (39444, 14)\n",
      "D4whhBS6cDZcxZTWQ SbXJngA5SJw6fX4X7 (299452, 14)\n",
      "o46tyNKeC4xHZeh7h kc7H5MybfG8z4QuAB (38262, 14)\n",
      "ByCLyAjbSNLZFD4pc oT9Y9S9wG9xzkCqTH (78868, 14)\n",
      "P63pMT9HvTtdmhWcL w6GrPdpwkjbsweeKC (135728, 14)\n",
      "cJzxLPbsT2xWzayjT 5WjAeATyNJQEBp2Jp (60265, 14)\n",
      "P63pMT9HvTtdmhWcL iqfzKWKpcHmcw3zyB (7442, 14)\n",
      "KkyhzzHqgJDFWPM9n boeYRjqKsN58hCttJ (0, 14)\n",
      "JjtbeWp3LdAJp4xME d8D9R65o75dzizwv7 (14795, 14)\n",
      "9aGAdAw3tYQ4MxCBc mBaukdLE4GfLJHMk3 (19408, 14)\n",
      "caH9RMynqjrmihrxA SMxaDCwvRkk9W5CYo (1051, 14)\n",
      "rgNDsz626CTLnd53Y vcSWQf42MRtpLdAyH (64324, 14)\n",
      "6DwQ3xhCWDGBRFFss bS7R8w9hgETJuiZoj (8526, 14)\n",
      "X28YzezeSoJRkQG5k nkezQjPpvGv3imnQC (187847, 14)\n",
      "6DwQ3xhCWDGBRFFss YLEEhTz7umoffAPqd (209708, 14)\n",
      "P63pMT9HvTtdmhWcL 6MixYQuZj8dX3wZaH (204964, 14)\n",
      "L7ME43C6TAoYv6HCb 4hmkTc8KYoncMnH59 (275058, 14)\n",
      "dPBnHGGKDN7BoewSb Pm6LiFkoePFdAKSaL (193177, 14)\n",
      "XvKkyKyMz4g2D7jr3 rJPS4snkZyiazJ5ba (9744, 14)\n",
      "7yxgKNbqd5PMNzX3P TdyAhrZWq6MDeyNvu (638, 14)\n",
      "j7MWhCyfRAgZstQdE BcggJ8dJgf6dG4HD6 (2103, 14)\n",
      "dPBnHGGKDN7BoewSb JTYN5fzmttm5Hp2nu (0, 14)\n",
      "rgNDsz626CTLnd53Y a99L3qQLhzu2mjmCT (9749, 14)\n",
      "AqJKG5gJ7MFSeX2Rp txeeYRyjoA8XKgudG (78885, 14)\n",
      "soGf2Qcrw8hz3zw7A hJnyq4aQmJ8ZPDN2p (120912, 14)\n",
      "W9FX7xfES6pZPg4o8 hoL6QWpKg4mFEEiB2 (9386, 14)\n",
      "WCoDEv4fPzofmrowz F83aT7SK4wCj9pGMR (176377, 14)\n",
      "hcLfFhKstdmNNtBjx stEZcHzK7YnStjxEY (0, 14)\n",
      "s4fnrie58B29225jc bhKv2q34nZ3pwig9G (244188, 14)\n",
      "iyMFa4iWBQcwDJ96J 7d2n9JxXJASYWzxxm (48950, 14)\n",
      "Q2ctDDsxjy23AoQLb 2yBx7nstyQ8ZsAmJr (64363, 14)\n",
      "9RfzKgXJn46NXH4Lm HiupCL6yiRpbhdTWC (38198, 14)\n",
      "KypyS8kNFhSPZxv7q ofeoiXgSPuM6PCyaN (131015, 14)\n",
      "YYejGWetywzcxRhn6 3KTQcT9Stpofdf5kB (87804, 14)\n",
      "EeKxS92bT8BmGsavE GR8ucGDAawJ8XkF94 (4110, 14)\n",
      "Q2ctDDsxjy23AoQLb Q2kMvxBHw5BF4acj3 (68443, 14)\n",
      "Q2ctDDsxjy23AoQLb qxiz5WYXaraD6m9cw (37134, 14)\n",
      "skr37kBKma2BsYjxM prYYNAY7hcMLYJzd9 (10544, 14)\n",
      "XQak5YK9eZfXYhKgJ wFgewqSvmGEQzyrLQ (63447, 14)\n",
      "HmNDEqWf2NvmYGpZu ZRSc2RYzna9Kni6Lo (78182, 14)\n",
      "s4fnrie58B29225jc wBbhHYEDp52BowBXg (96269, 14)\n",
      "hPzYzThkKMuQrF9Q2 kWheTth4u6uMC4CC9 (37298, 14)\n",
      "iJscrRfw6uYjEhEKo YzMPTXGLr6SqEDAWY (36184, 14)\n",
      "8fkcBjcmScuidkvn2 MuirNe829ZExjNmek (129405, 14)\n",
      "cSuhZSQExaug3odn5 iksYoAeKHCziH8wjb (1214, 14)\n",
      "FeYB32454Az4yNvon RFBbCqSpf2vmTqWfS (62817, 14)\n",
      "7SRQ7Z7xuN5EGXGSu hTZZG34NPtdCXgXvf (0, 14)\n",
      "H7LmfTFQfqAqxaeGf LPLszRsYMomFaBAQR (53016, 14)\n",
      "gmAmheWQLfWvhg7aF p5YBJDMCPA7PcwEDA (99499, 14)\n",
      "XQak5YK9eZfXYhKgJ 4AnrvwyLnHh4YXT7k (59828, 14)\n",
      "6K9bzPik9WxNFCceT nMdvN7zKuFLBwkye7 (158265, 14)\n",
      "iyMFa4iWBQcwDJ96J c8tpERbSmkRvaauEn (16623, 14)\n",
      "gMn8iLck9MHoDu2xn NCCNyEZrTpaHmptK6 (299053, 14)\n",
      "7SRQ7Z7xuN5EGXGSu JDcPyy6NfkQHkyK5C (229786, 14)\n",
      "uBkpbfZHy55ndgnTv JL5zpyFxo7J3rHxZK (175755, 14)\n",
      "dPBnHGGKDN7BoewSb noh5XdbxTK5gRSLMt (73560, 14)\n",
      "jfD4EGaLur6xsEHbQ 9qbx82jZwxnvdDDNX (29056, 14)\n",
      "my6fhmSxAxbdFvBKm Ttf4XqarkihAm2Fen (11555, 14)\n",
      "soGf2Qcrw8hz3zw7A hWwpRPYtQk9D9ub8S (46736, 14)\n",
      "rgNDsz626CTLnd53Y NsTkwrKuNqSPpjxJn (43474, 14)\n",
      "exFwNR5F4o5DGDKRW AmkkHfRm6RjhEJGrK (16941, 14)\n",
      "j7MWhCyfRAgZstQdE Xa54Pov4FpuTxizDd (2299, 14)\n",
      "D2JsangYtSFya4nDT G4yyguo4R7wGp3NR8 (36765, 14)\n",
      "QtFmR4Qgdk2fcYQ2h p4uoisdtyfqeYk4GX (41500, 14)\n",
      "jfD4EGaLur6xsEHbQ Wjgbcenow3oSALsgJ (32978, 14)\n",
      "E2ZWysfDHW2pqB7JW aYt5FfpYq2GnTagfC (92023, 14)\n",
      "kEYekxChnHJ5FRAc4 pwJ65xWrRyZ4QFJGP (22903, 14)\n",
      "FuDLDjBXzkEPPQxZD TgLFQQcK4NiY8unCE (104292, 14)\n",
      "KypyS8kNFhSPZxv7q RJxDzpLGARNoej3x9 (183455, 14)\n",
      "rrCXhvarvXo7P2fGo g63EjGYZsjHPqyPL4 (12608, 14)\n",
      "QZaMHjsdRoCrM6YpT fNwQTfW3g6RHFzem2 (274467, 14)\n",
      "kEYekxChnHJ5FRAc4 yTKh8QP9Yk7aQc7E3 (925, 14)\n",
      "dJg8Bmr3FDZhipSJe 43HM2Zu77qrMksWB8 (27120, 14)\n",
      "jHRWDbw2acLnecEMb Apjz33PejC6nxM44Q (43500, 14)\n",
      "kKBqnAwywSrKLGQpk qMqFJoMnwH5fYqfzc (8164, 14)\n",
      "NdvsZACyTb6HHHz5e GmRxcxhgYYbY4rzWt (117839, 14)\n",
      "hcLfFhKstdmNNtBjx WCXL3HhQzSr6kHaAX (26824, 14)\n",
      "7SRQ7Z7xuN5EGXGSu SrS9ay3mNoQzJ79ys (96588, 14)\n",
      "rgNDsz626CTLnd53Y wGDNyMATiZMDwrEAC (80754, 14)\n",
      "TETLayDXwuGSrkANd Prey6qWiR9qx42BfZ (31643, 14)\n",
      "4A5DE8Zj5gDtSmCbn JYAZRDbztXRLwJ5r6 (40491, 14)\n",
      "E64uo3RvNGNDpvzsD sLxB8GHBxW96yLLEc (80378, 14)\n",
      "jfD4EGaLur6xsEHbQ dRuDEyZkyY4YsToMD (12944, 14)\n",
      "dPBnHGGKDN7BoewSb GquEcaJjTtznA2SNW (24231, 14)\n",
      "soGf2Qcrw8hz3zw7A Fk7nnkg6WfWqTbA6r (111683, 14)\n",
      "E2ZWysfDHW2pqB7JW B8pM9KEBveyEBEN34 (32161, 14)\n",
      "s4fnrie58B29225jc Qzo8oZNzMzx2jL6sd (112256, 14)\n",
      "pTYqYSwRCuxLKKzME vWcpWc8k7eErZit6B (27454, 14)\n",
      "dbhjfjAkBf2xnrPDK NYG4r9zcLLg8dpuDT (136330, 14)\n",
      "rgNDsz626CTLnd53Y FiY6sP2fB5xgpo6W7 (55926, 14)\n",
      "Q2ctDDsxjy23AoQLb PRvKKPwhXmGoDXZeb (0, 14)\n",
      "cSnsbv7ccTEXcHAbW ssbs4evELKRzGP7Mg (15653, 14)\n",
      "nCruygGQCoYecWbiA hckksdjCgJZxCoSYx (68457, 14)\n",
      "SPYsqAwk5XEjp9ZwX CtuShNA5sgy8GnxMf (0, 14)\n",
      "E2ZWysfDHW2pqB7JW MbmydJAHsgpqFJJ4m (83161, 14)\n",
      "iJscrRfw6uYjEhEKo LFjsRXJPgxtXfFzxm (21258, 14)\n",
      "RqokibKjt6ueZK52s 4QHc4Kakc8PD8EJR8 (2068, 14)\n",
      "Q2ctDDsxjy23AoQLb vho4fBSgkDjiGBgup (63954, 14)\n",
      "dPBnHGGKDN7BoewSb bqKHM2aszQqLotXYD (45150, 14)\n",
      "wAcmr4LCaqm2w6LPx JzSkgYKPM4oTacbbF (49372, 14)\n",
      "7Grxab9AL8HbnNcCn J4qscTeHW28gWBxju (84745, 14)\n",
      "QeJpvdukLbF2jp29u MChwYqG2LnkKmdY55 (94764, 14)\n",
      "P63pMT9HvTtdmhWcL A9ZGNP4jxJfp8cErn (126709, 14)\n",
      "NpqM32uwNRKTTWTb6 hEDskKfvoCGHTkeDp (1978, 14)\n",
      "d2Q3Ga3jxiBpsHdHe mE6ABrbzCLjFDRiCK (44806, 14)\n",
      "pJRQ5CqncC9xk8bdy bmJuhcYDiqAcbj6Ze (63113, 14)\n",
      "dPBnHGGKDN7BoewSb 4H7u5h3YpH7AfhpRh (45439, 14)\n",
      "KkyhzzHqgJDFWPM9n 4syN56cW3Mz4jFb9b (0, 14)\n",
      "B9GQKa7DehxaHMtSX REZC5uHgzDKsSqNGB (37965, 14)\n",
      "KkyhzzHqgJDFWPM9n EuD42c5biCpsp7YAS (0, 14)\n",
      "KkyhzzHqgJDFWPM9n iSErbHS86nkF2ofqH (29967, 14)\n",
      "7R5MBJ2wAH328M9P7 kYM3JYW6yPzhuu8tE (45523, 14)\n",
      "E2ZWysfDHW2pqB7JW 5CAwD9Rt2kBXddaEC (34842, 14)\n",
      "rK3atC7axuLcz3iRB 7M2PxZuR7sPpfgfuJ (26586, 14)\n",
      "dWLm7ENAouJ4WEoJP wPF7B3axoELQhodfH (17424, 14)\n",
      "j7NR2ZFa5vXCAyxzR ZvfRr674sQivsWR89 (41593, 14)\n",
      "d7u39ZjnznjCCE54L eYoBctQZTqsmydrHY (26656, 14)\n",
      "GNPWTqYqZsfcAA6Jb FgmkhfmA7qPSkMsx4 (73227, 14)\n",
      "rgNDsz626CTLnd53Y X4umGyWwy8bByo3dp (60644, 14)\n",
      "ScA2tJQp3iryzrBKS fDrbnB9KCA2jnDbhg (82294, 14)\n",
      "6DwQ3xhCWDGBRFFss CaNMh4HdcNdPFkoYK (44384, 14)\n",
      "s4fnrie58B29225jc qh5yT7Q3YFa4RSMvW (240021, 14)\n",
      "SPYsqAwk5XEjp9ZwX eLHngApztHXt5s8EM (217217, 14)\n",
      "E2ZWysfDHW2pqB7JW EsDe4nRt3MX35cZkb (82976, 14)\n",
      "QZaMHjsdRoCrM6YpT HYarvKnCx8LimvPHd (741, 14)\n",
      "WFSExqQKtsq6W7At8 H3ZmnEr9cJwLp69KF (73214, 14)\n",
      "dPBnHGGKDN7BoewSb wGeAKkDSeYQb22QhS (60857, 14)\n",
      "P63pMT9HvTtdmhWcL 8XbpQa8QiwPcuxZbE (0, 14)\n",
      "czyNjjNhCHky7mjfu MDKfxxXkJLGffq9xg (59399, 14)\n",
      "4xWeGuAg4jDmZSWxA PY9ucfFTZc4XPSuPC (121311, 14)\n",
      "E2ZWysfDHW2pqB7JW 8w9LHWtFkywXHFbjT (98436, 14)\n",
      "gmAmheWQLfWvhg7aF rAffv9HziBbzRzqh3 (272086, 14)\n",
      "caH9RMynqjrmihrxA YWunBwEwPiKPDeiJB (3511, 14)\n",
      "DwAym344iPb22MYPr yji6wnh5kT8GZmM26 (99916, 14)\n",
      "JgeRNMvtP3A2tGcEo aBq33e9dcXdb9JRWR (111323, 14)\n",
      "ueTXJNrihTPQS97vZ Procfg9sDkYKKQDAr (20964, 14)\n",
      "pNvk32k66RwiH4XLW 35pY3nxKPGdfQKT28 (350164, 14)\n",
      "hbTCMydA4w2TnGqHE mN2gXpCGvAx4aMbit (268120, 14)\n",
      "KypyS8kNFhSPZxv7q hqoDkhKFbRGdjaC9Z (0, 14)\n",
      "gmAmheWQLfWvhg7aF aKiDRWpwJuhLABnWA (211878, 14)\n",
      "hRXNA7EETb3wW4HSM buYyQC35TaEXfna9g (40289, 14)\n"
     ]
    }
   ],
   "source": [
    "for company_id, location_id, location_sales_dataframe in company_location_dataframes:\n",
    "    # TODO: do data science stuff on these dataframes.\n",
    "    print(company_id, location_id, location_sales_dataframe.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96bb74a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9671f64f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
