{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyodbc\n",
    "from pathlib import Path\n",
    "from sqlalchemy import create_engine\n",
    "import numpy as np\n",
    "import urllib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Control"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "works for either just one file or multiple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = Path('../control_files').glob('*.csv')\n",
    "list_of_dfs = [pd.read_csv(file) for file in filenames]\n",
    "for dataframe, file in zip(list_of_dfs, filenames):\n",
    "    Dataframe['file'] = file\n",
    "df_file = pd.concat(list_of_dfs, ignore_index=True, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_file.rename(columns={'License Number': 'license_number', \n",
    "                   'License Type': 'license_type', \n",
    "                   'Business Owner': 'business_owner',\n",
    "                   'Business Contact Information': 'business_contact_information', \n",
    "                   'Business Structure': 'business_structure', \n",
    "                   'Premise Address': 'premise_address',\n",
    "                   'Status': 'status_curr', \n",
    "                   'Issue Date': 'date_issue', \n",
    "                   'Expiration Date': 'date_expiration',\n",
    "                    'Activities': 'business_description',\n",
    "                   'Adult-Use/Medicinal': 'adult_medicinal'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "drop \"TEMP\" licenses. These were all created in 2018 when industry started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_file.drop(df_file[df_file['license_number'].str.contains(\"TEMP\")].index, inplace=True)\n",
    "df_file.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are multiple lines that have the header name within the file. Reset index after dropping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_file.drop(df_file[df_file['license_number'] == 'License Number'].index, inplace=True)\n",
    "df_file.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "big Y for yyyy. small y for yy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_file['date_issue'] = pd.to_datetime(df_file['date_issue'], format=\"%m/%d/%Y\")\n",
    "df_file['date_expiration'] = pd.to_datetime(df_file['date_expiration'], format=\"%m/%d/%Y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_file['in_db'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get dummies for adult_medicinal. then assign both to adult/medicinal and eliminate both. add dummies back to original file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_dum = pd.get_dummies(df_file['adult_medicinal'])\n",
    "for i in range(len(df1_dum['BOTH'])):\n",
    "    if df1_dum[\"BOTH\"][i] == 1:\n",
    "        df1_dum['Adult-Use'][i] = 1\n",
    "        df1_dum['Medicinal'][i] = 1\n",
    "df1_dum.drop(columns=[\"BOTH\"], inplace=True)\n",
    "df1_dum.rename(columns={'Adult-Use': 'license_adult', 'Medicinal': 'license_medicinal'}, inplace=True)\n",
    "df_file = pd.concat([df_file, df1_dum], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get dummies for status. append \"status\" and make lower so dont need to change. add dummies back to original file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_dum_status = pd.get_dummies(df_file['status_curr'], prefix=\"status\")\n",
    "df1_dum_status.columns = map(str.lower, df1_dum_status.columns)\n",
    "df_file = pd.concat([df_file, df1_dum_status], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "add bureau of cannabis control to differentiate it when combined.\n",
    "Remove redundant cannabis and license words from the license type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_file['main_license_type'] = \"Bureau of Cannabis Control\"\n",
    "df_file['license_type'] = df_file['license_type'].str.replace(\"Cannabis - \", \"\")\n",
    "df_file['license_type'] = df_file['license_type'].str.replace(\"License\", \"\")\n",
    "df_file['license_type'] = df_file['license_type'].str.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "there are several owner names that have been merged into one column. Need to split each owner up individually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_file['business_owner'] = df_file['business_owner'].str.replace(\": :\", \":\")\n",
    "df_names_nan = df_file['business_owner'].str.split(':', expand=True)\n",
    "for i in range(len(df_names_nan.columns)):\n",
    "    df_names_nan[i] = df_names_nan[i].str.lower()\n",
    "    df_names_nan[i] = df_names_nan[i].str.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dropping duplicates across the row. sometimes owner name listed multiple times in same row. after duplicate names have been deleted, move the names one over to the left so there are not blanks in between names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_names_removed = df_names_nan.apply(lambda x: x.drop_duplicates(), axis=1)\n",
    "df2 = df_names_removed.apply(lambda x:pd.Series(x.dropna().values), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "renaming to make it easier when combining. only grabbing first two owners. the third column was only 0.42% (12 / 2812) of the whole df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_owner = df2.iloc[:,0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('mode.chained_assignment', None)\n",
    "for i in range(len(pd_owner.columns)):\n",
    "    pd_owner.rename(columns={i: 'contact_owner_{}'.format(i+1)}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loop through the split business contact information and if the column contains \"Email\" then append it to the email list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_biz_nan = df_file['business_contact_information'].str.split(' :', expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_email = None\n",
    "for i in range(len(df_biz_nan.columns)):\n",
    "    if pd_email is None:\n",
    "        pd_email = df_biz_nan[df_biz_nan[i].str.contains(\"Email\", na=False)][i]\n",
    "    else:    \n",
    "        pd_email = pd_email.append(df_biz_nan[df_biz_nan[i].str.contains(\"Email\", na=False)][i], ignore_index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if a company were to have a dba it would be in the second column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_dba = df_biz_nan[~df_biz_nan[1].str.contains(\"Email\", na=False)][1]\n",
    "pd_name = df_biz_nan[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loop through to add phone and website. concat all the series into one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_phone = None\n",
    "for i in range(len(df_biz_nan.columns)):\n",
    "    if pd_phone is None:\n",
    "        pd_phone = df_biz_nan[df_biz_nan[i].str.contains(\"Phone\", na=False)][i]\n",
    "    else:\n",
    "        pd_phone = pd_phone.append(df_biz_nan[df_biz_nan[i].str.contains(\"Phone\", na=False)][i], ignore_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_website = None\n",
    "for i in range(len(df_biz_nan.columns)):\n",
    "    if pd_website is None:\n",
    "        pd_website = df_biz_nan[df_biz_nan[i].str.contains(\"Website\", na=False)][i]\n",
    "    else:\n",
    "        pd_website = pd_website.append(df_biz_nan[df_biz_nan[i].str.contains(\"Website\", na=False)][i], ignore_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_biz_all = pd.concat([pd_name.rename(\"name_legal\"), pd_dba.rename(\"name_dba\"), pd_email.rename(\"contact_email\"), pd_phone.rename(\"contact_phone\"), pd_website.rename(\"contact_website\")], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cleaning up contact info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_biz_all['name_legal'] = pd_biz_all['name_legal'].str.strip()\n",
    "pd_biz_all['name_dba'] = pd_biz_all['name_dba'].str.strip()\n",
    "\n",
    "pd_biz_all['contact_email'] = pd_biz_all['contact_email'].str.replace(\"Email- \", \"\")\n",
    "pd_biz_all['contact_email'] = pd_biz_all['contact_email'].str.strip()\n",
    "\n",
    "pd_biz_all['contact_phone'] = pd_biz_all['contact_phone'].str.replace(\"Phone- \", \"\")\n",
    "pd_biz_all['contact_phone'] = pd_biz_all['contact_phone'].str.replace(\"-\", \"\")\n",
    "pd_biz_all['contact_phone'] = pd_biz_all['contact_phone'].str.replace(\"(\", \"\")\n",
    "pd_biz_all['contact_phone'] = pd_biz_all['contact_phone'].str.replace(\")\", \"\")\n",
    "pd_biz_all['contact_phone'] = pd_biz_all['contact_phone'].str.replace(\" \", \"\")\n",
    "pd_biz_all['contact_phone'] = pd_biz_all['contact_phone'].str.strip()\n",
    "\n",
    "pd_biz_all['contact_website'] = pd_biz_all['contact_website'].str.replace(\"Website- \", \"\")\n",
    "pd_biz_all['contact_website'] = pd_biz_all['contact_website'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_file.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd_all = pd.concat([pd_biz_all, pd_owner, pd_zip_county], axis=1)\n",
    "pd_all = pd.concat([pd_biz_all, pd_owner], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_control = pd.concat([df_file, pd_all], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_control.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_control.drop(columns=['business_owner', \n",
    "                     'business_contact_information', \n",
    "#                      'premise_address', \n",
    "                     'status_curr', \n",
    "                     'adult_medicinal'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_control.rename(columns={\n",
    "'license_type' : 'license_description',\n",
    "'business_structure' : 'business_company_type',\n",
    "'main_license_type' : 'license_category'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_control.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_control.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Manufacture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = Path('../manufacture_files').glob('*.csv')\n",
    "list_of_dfs = [pd.read_csv(file, header=1) for file in filenames]\n",
    "for dataframe, file in zip(list_of_dfs, filenames):\n",
    "    Dataframe['file'] = file\n",
    "\n",
    "df_file_m = pd.concat(list_of_dfs, ignore_index=True, sort=False)\n",
    "len(df_file_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_file_m.rename(columns={\n",
    "'BUSINESS LEGAL NAME': 'name_legal', \n",
    "'BUSINESS DBA NAME': 'name_dba', \n",
    "'LICENSE NUMBER': 'license_number',\n",
    "'PREMISES CITY': 'contact_city', \n",
    "'STATUS': 'status', \n",
    "'LICENSE CATEGORY': 'license_category', \n",
    "'PREMISES EMAIL': 'contact_email',\n",
    "'EFFECTIVE DATE': 'date_issue', \n",
    "'LICENSE TYPE': 'license_description', \n",
    "'PREMISES PHONE': 'contact_phone', \n",
    "'EXPIRATION DATE': 'date_expiration',\n",
    "'PREMISES COUNTY': 'contact_county', \n",
    "'ANNUAL/PROVISIONAL': 'annual_provisional'  \n",
    "}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_file_m['date_issue'] = pd.to_datetime(df_file_m['date_issue'], format=\"%m/%d/%Y\")\n",
    "df_file_m['date_expiration'] = pd.to_datetime(df_file_m['date_expiration'], format=\"%m/%d/%Y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if phone type is int then dont need to remove \"-\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_file_m['contact_phone'].dtype\n",
    "# pd_biz_all['contact_phone'] = pd_biz_all['contact_phone'].str.replace(\"-\", \"\")\n",
    "# df_file_m['contact_phone'].str.contains(\"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_file_m['in_db'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get dummies for status column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "active_dum = pd.get_dummies(df_file_m['status'], prefix=\"status\")\n",
    "active_dum.columns = map(str.lower, active_dum.columns)\n",
    "df_file_m = pd.concat([df_file_m, active_dum], axis=1)\n",
    "df_file_m.drop(columns='status', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get dummies for license category. basically adds the column if it doesnt exist so it can loop through."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_dum = pd.get_dummies(df_file_m['license_category'])\n",
    "category_dum.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'Adult Use' not in category_dum.columns:\n",
    "    category_dum['license_adult'] = 0\n",
    "else:\n",
    "    category_dum.rename(columns={'Adult Use': 'license_adult'}, inplace=True)\n",
    "    \n",
    "if 'Medicinal' not in category_dum.columns:\n",
    "    category_dum['license_medicinal'] = 0\n",
    "else:\n",
    "    category_dum.rename(columns={'Medicinal': 'license_medicinal'}, inplace=True)\n",
    "    \n",
    "if 'Adult and Medicinal' in category_dum.columns:\n",
    "    for i in range(len(category_dum)):\n",
    "        if category_dum[\"Adult and Medicinal\"][i] == 1:\n",
    "            category_dum['license_adult'][i] = 1\n",
    "            category_dum['license_medicinal'][i] = 1\n",
    "    category_dum.drop(columns='Adult and Medicinal', inplace=True)\n",
    "\n",
    "df_file_m = pd.concat([df_file_m, category_dum], axis=1)\n",
    "df_file_m.drop(columns='license_category', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get dummies for annual / provisional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annual_dum = pd.get_dummies(df_file_m['annual_provisional'], prefix='license')\n",
    "annual_dum.columns = map(str.lower, annual_dum.columns)\n",
    "df_file_m = pd.concat([df_file_m, annual_dum], axis=1)\n",
    "df_file_m.drop(columns='annual_provisional', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "modifiy the contact info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_file_m['contact_city'] = df_file_m['contact_city'].str.lower()\n",
    "df_file_m['contact_city'] = df_file_m['contact_city'].str.strip()\n",
    "\n",
    "df_file_m['contact_county'] = df_file_m['contact_county'].str.replace(\"County\", \"\")\n",
    "df_file_m['contact_county'] = df_file_m['contact_county'].str.lower()\n",
    "df_file_m['contact_county'] = df_file_m['contact_county'].str.strip()\n",
    "\n",
    "df_file_m['contact_state'] = 'CA'\n",
    "\n",
    "df_file_m['license_category'] = 'Manufactured Cannabis License'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Cultivation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two versions. Can either manually combine the two tabs into one or can treat each tab as a separate workbook. The provisional DRP typically has about 25 that the business one does not have.\n",
    "\n",
    "Also the lists don't include \"Expired - Pending Renewal\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = Path('../cultivation_files').glob('*.csv')\n",
    "# list_of_dfs = [pd.read_csv(file) for file in filenames]\n",
    "\n",
    "# Only use this when the above code doesn't work.\n",
    "list_of_dfs = [pd.read_csv(file, encoding=\"ISO-8859-1\") for file in filenames]\n",
    "\n",
    "for dataframe, file in zip(list_of_dfs, filenames):\n",
    "    Dataframe['file'] = file\n",
    "\n",
    "cult_df = pd.concat(list_of_dfs, ignore_index=True, sort=False)\n",
    "len(cult_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reminder - when editing the file just use issuance date and then can remove the below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cult_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cult_df.rename(columns={'Valid From Date':'Issuance Date'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "drop temp licenses, then reset index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cult_df.drop(cult_df[cult_df['License Type'] == 'Temporary Cannabis Cultivation License'].index, inplace=True)\n",
    "cult_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cult_df.drop(cult_df[cult_df['License Type'] == 'Cultivation License Renewal'].index, inplace=True)\n",
    "cult_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cult_df['Issuance Date'] = pd.to_datetime(cult_df['Issuance Date'], format=\"%m/%d/%Y\")\n",
    "cult_df['Expiration Date'] = pd.to_datetime(cult_df['Expiration Date'], format=\"%m/%d/%Y\")\n",
    "# cult_df['contact_owner_1'] = cult_df['First Name'] + \" \" + cult_df['Last Name']\n",
    "cult_df['in_db'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "drop and rename columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cult_df.drop(columns=['APN', 'First Name', 'Last Name', 'Title'], inplace=True)\n",
    "\n",
    "cult_df.rename(columns={\n",
    "# 'Legal Business Name': 'name',\n",
    "'ï»¿Legal Business Name': 'name',\n",
    "'E-Mail': 'contact_email',\n",
    "# 'Phone Number': 'contact_phone',\n",
    "'License Type': 'license_category',\n",
    "'Type of License': 'license_type',\n",
    "'License Number': 'license_number',\n",
    "'License Status': 'status',\n",
    "'Issuance Date': 'date_issue',\n",
    "'Expiration Date': 'date_expiration',\n",
    "# 'Premise Address': 'contact_street',\n",
    "# 'Premise City': 'contact_city',\n",
    "# 'Premise County': 'contact_county',\n",
    "# 'Premise Zip': 'contact_zip'\n",
    "}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get dummies for status. change about to expire to active. add back to main df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_dum = pd.get_dummies(cult_df['status'], prefix='status')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_dum.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'status_About to Expire' in df1_dum.columns:\n",
    "    if 'status_Active' in df1_dum.columns:\n",
    "        df1_dum['status_active'] = df1_dum['status_About to Expire'] + df1_dum['status_Active']\n",
    "        df1_dum.drop(columns={'status_About to Expire', 'status_Active'}, inplace=True)\n",
    "#         df1_dum.columns = map(str.lower, df1_dum.columns)\n",
    "#     elif 'status_Active' not in df1_dum.columns:\n",
    "#         df1_dum['status_active'] = df1_dum['status_About to Expire']\n",
    "#         df1_dum.drop(columns={'status_About to Expire'})\n",
    "#         df1_dum.columns = map(str.lower, df1_dum.columns)\n",
    "# elif 'status_About to Expire' not in df1_dum.columns:\n",
    "#         df1_dum.columns = map(str.lower, df1_dum.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'status_Expired - Pending Renewal' in df1_dum.columns:\n",
    "    if 'status_Expired' in df1_dum.columns:\n",
    "        df1_dum['status_expired'] = df1_dum['status_Expired - Pending Renewal'] + df1_dum['status_Expired']\n",
    "        df1_dum.drop(columns={'status_Expired - Pending Renewal', 'status_Expired'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_dum.columns = map(str.lower, df1_dum.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_dum.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cult_df = pd.concat([cult_df, df1_dum], axis=1)\n",
    "cult_df.drop(columns='status', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "split license type then concat. add back license description. remove license type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_license = cult_df['license_type'].str.split(' - ', expand=True)\n",
    "df_adult = pd.get_dummies(df_license[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_adult.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_adult['license_adult'] = df_adult['Adult-Use'] + df_adult['Annual Adult-Use'] + df_adult['Provisional Adult-Use']\n",
    "df_adult['license_adult'] = df_adult['Annual Adult-Use'] + df_adult['Provisional Adult-Use']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_adult['license_medicinal'] = df_adult['Annual Medicinal'] + df_adult['Provisional Medicinal']\n",
    "# df_adult['license_medicinal'] = df_adult['Annual Medicinal'] + df_adult['Provisional Medicinal'] + df_adult['Medicinal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_adult['license_provisional'] = df_adult['Provisional Adult-Use'] + df_adult['Provisional Medicinal']\n",
    "df_ad_md_pr = df_adult[['license_adult', 'license_medicinal', 'license_provisional']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cult_df = pd.concat([cult_df, df_ad_md_pr], axis=1)\n",
    "\n",
    "df_license.rename(columns={1:'license_description'}, inplace=True)\n",
    "cult_df = pd.concat([cult_df, df_license['license_description']], axis=1)\n",
    "cult_df.drop(columns=['license_type'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "edit county and phone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cult_df['contact_county'] = cult_df['contact_county'].str.replace(\"County\", \"\")\n",
    "# cult_df['contact_county'] = cult_df['contact_county'].str.lower()\n",
    "# cult_df['contact_county'] = cult_df['contact_county'].str.strip()\n",
    "\n",
    "# cult_df['contact_phone'] = cult_df['contact_phone'].str.replace(\"-\", \"\")\n",
    "# cult_df['contact_phone'] = cult_df['contact_phone'].str.replace(\" \", \"\")\n",
    "# cult_df['contact_phone'] = cult_df['contact_phone'].str.strip()\n",
    "\n",
    "cult_df['contact_state'] = 'CA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#good way to check if numbers dont have any other characters, if the below works\n",
    "# cult_df.astype({'contact_phone': float})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "need to make name lowercase so that it catches all of the DBA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cult_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cult_df['name'] = cult_df['name'].str.lower()\n",
    "\n",
    "if len(cult_df[cult_df['name'].str.contains(\"dba\", na=False)]) > 0:\n",
    "    df_dba = cult_df['name'].str.split(\"dba\", expand=True)\n",
    "    df_dba[0] = df_dba[0].str.strip()\n",
    "    df_dba[1] = df_dba[1].str.strip()\n",
    "    df_dba.rename(columns={0: 'name_legal', 1: 'name_dba'}, inplace=True)\n",
    "    cult_df = pd.concat([cult_df, df_dba], axis=1)\n",
    "    cult_df.drop(columns=['name'], inplace=True)\n",
    "else:\n",
    "    cult_df.rename(columns={'name': 'name_legal'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine All"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "combine all the dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.concat([df_control, df_file_m, cult_df], axis=0, sort=False)\n",
    "df_all.reset_index(drop=True, inplace=True)\n",
    "len(df_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### make sure to edit. create date uploaded column. rearrange the columns to make it easier for editing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['date_uploaded'] = pd.datetime(2020, 10, 21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = df_all[[\n",
    "    'license_number', 'license_category','license_description','license_adult','license_medicinal','license_annual','license_provisional',\n",
    "    'name_legal', 'name_dba', \n",
    "    'date_issue', 'date_expiration', \n",
    "    'status_active','status_canceled', 'status_expired', 'status_inactive','status_revoked', 'status_surrendered', 'status_suspended',\n",
    "    'business_description', 'business_company_type',\n",
    "    'contact_email','contact_phone','contact_website', 'contact_owner_1','contact_owner_2', \n",
    "#     'contact_street',\n",
    "    'contact_city','contact_county','contact_state', \n",
    "#     'contact_zip', \n",
    "    'date_uploaded',\n",
    "    'in_db',\n",
    "]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "assign names to NaN / blank name_legal. not using contact information as it could get confusing. if the name from the csv is \"N/A\", it gets converted to NaN after it's brought in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_name_legal_null = df_all[(df_all['name_legal'] == \"\") | (df_all['name_legal'].isnull()) | (df_all['name_legal'] == 'no legal business name provided')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_name_legal_null)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### change date for date of file yyyymmdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assign_date = '20210113'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('mode.chained_assignment', None)\n",
    "\n",
    "for i in range(len(df_name_legal_null)):\n",
    "    df_name_legal_null['name_legal'].iloc[i] = 'name_legal_null_' + assign_date + \"_\" + str(i)\n",
    "\n",
    "df_all = df_all.append(df_name_legal_null)\n",
    "df_all.drop_duplicates(subset='license_number', keep='last', inplace=True)\n",
    "df_all.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Roll up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnxn = pyodbc.connect(server = 'bespoke-database-1.cmevrozrcs7c.us-west-2.rds.amazonaws.com', \n",
    "                      driver = '{ODBC Driver 17 for SQL Server}',\n",
    "                      database = 'ca_cannabis',\n",
    "                      UID = 'admin',\n",
    "                      PWD = 'N19lrqxnurTUJLJT6GFe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_roll = pd.read_sql(\"SELECT * FROM ca_roll\", cnxn)\n",
    "len(df_roll)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "remove dash \"-\" with space and \":\" - with extra space or no?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_all[df_all['name_legal_clean'].str.contains(\"-\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['name_legal_clean'] = df_all['name_legal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('mode.chained_assignment', None)\n",
    "\n",
    "df_all['name_legal_clean'] = df_all['name_legal_clean'].str.lower() \n",
    "df_all['name_legal_clean'] = df_all['name_legal_clean'].str.replace(r\"\\b, inc.\\b\", \"\")\n",
    "df_all['name_legal_clean'] = df_all['name_legal_clean'].str.replace(r\"\\binc.\\b\", \"\")\n",
    "df_all['name_legal_clean'] = df_all['name_legal_clean'].str.replace(r\"\\binc\\b\", \"\")\n",
    "df_all['name_legal_clean'] = df_all['name_legal_clean'].str.replace(r\"\\b, llc.\\b\", \"\") \n",
    "df_all['name_legal_clean'] = df_all['name_legal_clean'].str.replace(r\"\\b, llc\\b\", \"\")\n",
    "df_all['name_legal_clean'] = df_all['name_legal_clean'].str.replace(r\"\\b, l.l.c.\\b\", \"\") \n",
    "df_all['name_legal_clean'] = df_all['name_legal_clean'].str.replace(r\"\\bllc\\b\", \"\")\n",
    "df_all['name_legal_clean'] = df_all['name_legal_clean'].str.replace(r\"\\bcorp.\\b\", \"\")\n",
    "df_all['name_legal_clean'] = df_all['name_legal_clean'].str.replace(r\"\\bcorp\\b\", \"\")\n",
    "df_all['name_legal_clean'] = df_all['name_legal_clean'].str.replace(r\"\\bcorporation\\b\", \"\")\n",
    "df_all['name_legal_clean'] = df_all['name_legal_clean'].str.replace(r\"\\bco.\\b\", \"\")\n",
    "df_all['name_legal_clean'] = df_all['name_legal_clean'].str.replace(r\"\\bco\\b\", \"\")\n",
    "df_all['name_legal_clean'] = df_all['name_legal_clean'].str.replace(\",\", \"\")\n",
    "df_all['name_legal_clean'] = df_all['name_legal_clean'].str.replace(\".\", \"\")\n",
    "df_all['name_legal_clean'] = df_all['name_legal_clean'].str.replace(\"'\", \"\")\n",
    "df_all['name_legal_clean'] = df_all['name_legal_clean'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('mode.chained_assignment', None)\n",
    "\n",
    "df_roll['company_roll_up'] = df_roll['company_roll_up'].str.lower() \n",
    "df_roll['company_roll_up'] = df_roll['company_roll_up'].str.replace(r\"\\b, inc.\\b\", \"\")\n",
    "df_roll['company_roll_up'] = df_roll['company_roll_up'].str.replace(r\"\\binc.\\b\", \"\")\n",
    "df_roll['company_roll_up'] = df_roll['company_roll_up'].str.replace(r\"\\binc\\b\", \"\")\n",
    "df_roll['company_roll_up'] = df_roll['company_roll_up'].str.replace(r\"\\b, llc.\\b\", \"\") \n",
    "df_roll['company_roll_up'] = df_roll['company_roll_up'].str.replace(r\"\\b, llc\\b\", \"\")\n",
    "df_roll['company_roll_up'] = df_roll['company_roll_up'].str.replace(r\"\\b, l.l.c.\\b\", \"\") \n",
    "df_roll['company_roll_up'] = df_roll['company_roll_up'].str.replace(r\"\\bllc\\b\", \"\")\n",
    "df_roll['company_roll_up'] = df_roll['company_roll_up'].str.replace(r\"\\bcorp.\\b\", \"\")\n",
    "df_roll['company_roll_up'] = df_roll['company_roll_up'].str.replace(r\"\\bcorp\\b\", \"\")\n",
    "df_roll['company_roll_up'] = df_roll['company_roll_up'].str.replace(r\"\\bcorporation\\b\", \"\")\n",
    "df_roll['company_roll_up'] = df_roll['company_roll_up'].str.replace(r\"\\bco.\\b\", \"\")\n",
    "df_roll['company_roll_up'] = df_roll['company_roll_up'].str.replace(r\"\\bco\\b\", \"\")\n",
    "df_roll['company_roll_up'] = df_roll['company_roll_up'].str.replace(\",\", \"\")\n",
    "df_roll['company_roll_up'] = df_roll['company_roll_up'].str.replace(\".\", \"\")\n",
    "df_roll['company_roll_up'] = df_roll['company_roll_up'].str.replace(\"'\", \"\") #not sure if this will work?\n",
    "df_roll['company_roll_up'] = df_roll['company_roll_up'].str.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "merge with df roll to assign roll up id. df_all_fill is the df that does NOT have any missing roll up id. company_nan is the df that HAS missing roll up id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_merge = df_all.merge(df_roll, on='license_number', how='left')\n",
    "df_all_fill = df_all_merge.dropna(subset=['roll_up_id'])\n",
    "company_nan = df_all_merge[df_all_merge['roll_up_id'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(df_all_merge) == len(df_all_fill) + len(company_nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "drop roll up id and company roll up as they are going to be added in the merge (company_nan). take only the roll up id and company roll up (take out license #) and then drop duplicates across both columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "company_nan_drop = company_nan.drop(columns=['roll_up_id', 'company_roll_up'])\n",
    "df_roll_name_only = df_roll[['roll_up_id', 'company_roll_up']]\n",
    "df_roll_name_only.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "combine based on the name in the company roll up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "company_nan_merge = pd.merge(company_nan_drop, df_roll_name_only, left_on='name_legal_clean', \n",
    "                             right_on='company_roll_up', how='left', suffixes=('', '_y'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "combine the df that does not have missing items to the one that was just populated based on name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = df_all_fill.append(company_nan_merge, sort=False)\n",
    "df_final.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.sort_values(['name_legal_clean'], ascending=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "don't change the info except for contact / roll up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "add column changed contact info if changes need to be made while editing file. this only makes sense if i am editing the new items. need to change it so that i can view the already altered information with the new items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final['changed_contact_info'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_contact = pd.read_sql(\"SELECT * FROM ca_contact\", cnxn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main = pd.read_sql(\"SELECT * FROM ca_main\", cnxn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main0['license_number'].isin(sql_main['license_number']).astype(int)\n",
    "# df_final[df_final['license_number'].isin(df_main['license_number'])]\n",
    "df_final['in_sql'] = df_final['license_number'].isin(df_main['license_number']).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_add = df_final[df_final['in_sql'] == 0]\n",
    "len(df_final_add.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_exist = df_final[df_final['in_sql'] == 1]\n",
    "len(df_final_exist.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_exist_min = df_final_exist[['license_number',  #1\n",
    "                               'license_category', \n",
    "                               'license_description',\n",
    "                               'license_adult', \n",
    "                                'license_medicinal', #5 \n",
    "                               'license_annual',\n",
    "                               'license_provisional',\n",
    "                                'name_legal', \n",
    "                               'name_dba', \n",
    "                               'name_legal_clean', #10\n",
    "                                'date_issue',\n",
    "                               'date_expiration', \n",
    "                                'status_active', \n",
    "                               'status_canceled', \n",
    "                               'status_expired',\n",
    "                               'status_inactive', \n",
    "                                'status_revoked', \n",
    "                               'status_surrendered', #20\n",
    "                               'status_suspended', \n",
    "                                'business_description', \n",
    "                               'business_company_type',\n",
    "                                'company_roll_up', \n",
    "                               'roll_up_id', #25\n",
    "                                'changed_contact_info',\n",
    "                               'date_uploaded', \n",
    "                               'in_db', \n",
    "                               'in_sql']] #29"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sql_merge = df_exist_min.merge(df_contact, on='license_number')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_edit = df_sql_merge.append(df_final_add, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_edit.sort_values(['name_legal_clean'], ascending=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_edit = df_to_edit[['license_number', 'license_category', 'license_description','license_adult', \n",
    "                    'license_medicinal', 'license_annual','license_provisional',\n",
    "                    'name_legal', 'name_dba', 'name_legal_clean', 'roll_up_id', 'company_roll_up',\n",
    "                    'date_issue','date_expiration', \n",
    "                    'status_active', 'status_canceled', 'status_expired','status_inactive', \n",
    "                    'status_revoked', 'status_surrendered','status_suspended', \n",
    "                    'business_description', 'business_company_type',\n",
    "                    'contact_email', 'contact_phone', 'contact_website', 'contact_owner_1',\n",
    "                    'contact_owner_2', 'contact_street', 'contact_city', 'contact_county',\n",
    "                    'contact_state', 'contact_zip', 'changed_contact_info',\n",
    "                    'date_uploaded', 'in_db', 'in_sql']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(df_to_edit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_to_edit[df_to_edit['roll_up_id'] != \"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change Date yyyymmdd\n",
    "df_to_edit.to_csv('../edited_files/df_final_20210113_to_edit.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAKE EDITS TO FILE BEFORE GOING FURTHER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in Edited"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only update contact info and roll up from edited file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change Date yyyymmdd\n",
    "df_edited = pd.read_csv('../edited_files/df_final_20210113_to_edit.csv')\n",
    "len(df_edited)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is Nolan added code to check that he didn't forget to add company_roll_ups\n",
    "if len(df_edited[df_edited['company_roll_up'].isnull()]) == 0:\n",
    "    print(\"Continue\")\n",
    "else:\n",
    "    print(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_edited = pd.read_csv('../edited_files/df_final_20200527_edited.csv')\n",
    "# len(df_edited)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "split df_edited into ones where roll up id has been populated and where they have not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_edited_fill = df_edited.dropna(subset=['roll_up_id'])\n",
    "df_edited_null = df_edited[df_edited['roll_up_id'].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "take all the unique company names and then give them an id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_roll['roll_up_id'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_roll['roll_up_id'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_missing = df_edited_null['company_roll_up'].unique()\n",
    "max_val = df_roll['roll_up_id'].max() + 1\n",
    "\n",
    "num_vals = len(names_missing)\n",
    "array_list = []\n",
    "for i in range(num_vals):\n",
    "    array_list.append(max_val)\n",
    "    max_val += 1\n",
    "\n",
    "id_array = np.asarray(array_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "below i am creating a database of of the unique names (names_missing) and the ids that were created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_miss_fill = pd.DataFrame({'company_roll_up': names_missing, 'roll_up_id': id_array})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "drop roll up id because then it will be added on merge from the loop created above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_edited_null.drop(columns='roll_up_id', inplace=True)\n",
    "df_edited_pop = df_edited_null.merge(pd_miss_fill, on='company_roll_up', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "adding back the previously populated with the new populated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_populated = df_edited_fill.append(df_edited_pop, sort=False)\n",
    "len(df_populated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "change from df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main = df_populated[['license_number','license_category','license_description','license_adult','license_medicinal',\n",
    "                       'license_annual','license_provisional','name_legal','name_dba','date_issue','date_expiration',\n",
    "                       'status_active','status_canceled','status_expired','status_revoked','status_surrendered',\n",
    "                       'status_suspended','business_description','business_company_type','date_uploaded','in_db']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main = df_edited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Added infer_datetime_format=True to deal with reuccuring error.\n",
    "\n",
    "df_main['date_issue'] = pd.to_datetime(df_main['date_issue'], infer_datetime_format=True, format=\"%m/%d/%Y\")\n",
    "df_main['date_expiration'] = pd.to_datetime(df_main['date_expiration'], infer_datetime_format=True, format=\"%m/%d/%Y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_contact = df_populated[['license_number','contact_email','contact_phone','contact_website','contact_owner_1',\n",
    "                           'contact_owner_2','contact_street','contact_city','contact_county','contact_state','contact_zip',\n",
    "                          'changed_contact_info']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_roll = df_populated[['license_number', 'roll_up_id', 'company_roll_up']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_main[df_main.duplicated(subset='license_number')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare to SQL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnxn = pyodbc.connect(server = 'bespoke-database-1.cmevrozrcs7c.us-west-2.rds.amazonaws.com', \n",
    "                      driver = '{ODBC Driver 17 for SQL Server}',\n",
    "                      database = 'ca_cannabis',\n",
    "                      UID = 'admin',\n",
    "                      PWD = 'N19lrqxnurTUJLJT6GFe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_main = pd.read_sql(\"SELECT * FROM ca_main\", cnxn)\n",
    "sql_main['in_db'] = 1\n",
    "len(sql_main)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "change the names to all lowercase so that it will drop duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_main['name_legal'] = sql_main['name_legal'].str.lower()\n",
    "sql_main['name_dba'] = sql_main['name_dba'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main['name_legal'] = df_main['name_legal'].str.lower()\n",
    "df_main['name_dba'] = df_main['name_dba'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_all = sql_main.append(df_main, ignore_index=True)\n",
    "len(main_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_all.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fill na as 0 so it's not marked as none. help with deleting duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_drop = main_all.drop_duplicates(subset=['license_number', 'license_category', 'license_description',\n",
    "       'license_adult', 'license_medicinal', 'license_annual',\n",
    "       'license_provisional', 'name_legal', 'name_dba', 'date_issue',\n",
    "       'date_expiration', 'status_active', 'status_canceled', 'status_expired',\n",
    "       'status_revoked', 'status_surrendered', 'status_suspended',\n",
    "       'business_description', 'business_company_type'], keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_drop.reset_index(drop=True, inplace=True)\n",
    "len(main_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(main_drop)):\n",
    "    if main_drop['name_dba'].iloc[i] == '0':\n",
    "        main_drop['name_dba'].iloc[i] = 0\n",
    "    if main_drop['business_description'].iloc[i] == '0':\n",
    "        main_drop['business_description'].iloc[i] = 0\n",
    "    if main_drop['business_company_type'].iloc[i] == '0':\n",
    "        main_drop['business_company_type'].iloc[i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_drop.drop_duplicates(subset=['license_number', 'license_category', 'license_description',\n",
    "       'license_adult', 'license_medicinal', 'license_annual',\n",
    "       'license_provisional', 'name_legal', 'name_dba', 'date_issue',\n",
    "       'date_expiration', 'status_active', 'status_canceled', 'status_expired',\n",
    "       'status_revoked', 'status_surrendered', 'status_suspended',\n",
    "       'business_description', 'business_company_type'], keep='first', inplace=True)\n",
    "\n",
    "main_drop.reset_index(drop=True, inplace=True)\n",
    "len(main_drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_main[df_main['name_legal'].str.contains(\"’\")]\n",
    "# df_main['name_legal'] = df_main['name_legal'].str.replace(\"’\", \"'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main_drop[main_drop.duplicated(subset='license_number')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main_drop[main_drop['license_number'] == 'C13-0000016-LIC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main_drop.iloc[320] == main_drop.iloc[9339]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main_drop.iloc[9338]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "had some issues where some dba names were listed as string 0 not numeric 0 and so they were not dropping when removing duplicates. unsure if this is an ongoing problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main_drop[main_drop['name_dba'] == '0']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "need to to the same thing for business description and business company type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "separate out where in_db = 0. creating a column called exists_db. It looks to see if the license number exists in the sql database. main_add are the license numbers that do not exist in the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main_drop[main_drop['in_db'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main0['license_number'].isin(sql_main['license_number']).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main0[main0['exists_db'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main0 = main_drop[main_drop['in_db'] == 0]\n",
    "main0['exists_db'] = main0['license_number'].isin(sql_main['license_number']).astype(int)\n",
    "main_add = main0[main0['exists_db'] == 0]\n",
    "len(main_add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_add.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "drop the exists column as it is not in the database table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_add.drop(columns='exists_db', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "note - need to go in and change all the ones in the table to in_db = 1. i think i did not change it when initially uploading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_add['in_db'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main_add.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding line items to SQL table ca_main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = urllib.parse.quote_plus(\"DRIVER={ODBC Driver 17 for SQL Server};\"\n",
    "                                 \"SERVER=bespoke-database-1.cmevrozrcs7c.us-west-2.rds.amazonaws.com;\"\n",
    "                                 \"DATABASE=ca_cannabis;\"\n",
    "                                 \"UID=admin;\"\n",
    "                                 \"PWD=N19lrqxnurTUJLJT6GFe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(\"mssql+pyodbc:///?odbc_connect={}\".format(params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Comparing\n",
    "\n",
    "# main_add.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Comparing\n",
    "\n",
    "# pd.read_sql('ca_main', con=engine).tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this only if there are extra columns again.\n",
    "\n",
    "ca_main_columns=['license_number', 'license_category', 'license_description',\n",
    "       'license_adult', 'license_medicinal', 'license_annual',\n",
    "       'license_provisional', 'name_legal', 'name_dba', 'date_issue',\n",
    "       'date_expiration', 'status_active', 'status_canceled', 'status_expired',\n",
    "       'status_revoked', 'status_surrendered', 'status_suspended',\n",
    "       'business_description', 'business_company_type', 'date_uploaded',\n",
    "       'in_db']\n",
    "\n",
    "for column in main_add.columns:\n",
    "    if column not in ca_main_columns:\n",
    "        main_add = main_add.drop(columns=column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "main_add.to_sql('ca_main', con=engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_alter = main0[main0['exists_db'] == 1]\n",
    "len(main_alter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main_alter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_alter.drop(columns='exists_db', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_alter['in_db'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### need to export to excel to manually update SQL through SQL server import / export to make changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change Date mm_dd_yy\n",
    "main_alter.to_excel('../edited_files/main_alter_01_13_21.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "would rather have a check internally if the name legal or name dba has changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contact"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "going to have to add in a column 'edit_contact' of 1 and 0 that I mark off when editing to decipher which ones to then update in contact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_contact = pd.read_sql(\"SELECT * FROM ca_contact\", cnxn)\n",
    "len(sql_contact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_contact['in_db'] = 1\n",
    "sql_contact['changed_contact_info'] = 0\n",
    "\n",
    "df_contact['in_db'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contact_all = sql_contact.append(df_contact, ignore_index=True, sort=False)\n",
    "contact_all.fillna(0, inplace=True)\n",
    "len(contact_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# contact_drop.in_db.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contact_drop = contact_all.drop_duplicates(subset=['license_number'], keep='first')\n",
    "len(contact_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contact_drop.in_db.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contact0 = contact_drop[contact_drop['in_db'] == 0]\n",
    "len(contact0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "below is the one to add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contact0.drop(columns=['in_db', 'changed_contact_info'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(\"mssql+pyodbc:///?odbc_connect={}\".format(params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contact0.to_sql('ca_contact', con=engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to alter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contact_add = contact_all[contact_all['changed_contact_info'] == 1]\n",
    "len(contact_add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contact_add.drop(columns=['in_db', 'changed_contact_info'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Roll Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "come up with way to alter company roll up ids "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_roll = pd.read_sql(\"SELECT * FROM ca_roll\", cnxn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sql_roll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_roll['in_db'] = 1\n",
    "df_roll['in_db'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roll_all = sql_roll.append(df_roll, ignore_index=True)\n",
    "len(roll_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roll_drop = roll_all.drop_duplicates(subset=['license_number'], keep='first')\n",
    "len(roll_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roll0 = roll_drop[roll_drop['in_db'] == 0]\n",
    "len(roll0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roll0['exists_db'] = roll0['license_number'].isin(sql_roll['license_number']).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roll_add = roll0[roll0['exists_db'] == 0]\n",
    "len(roll_add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roll_add.drop(columns='exists_db', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# roll_add['in_db'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roll_add.drop(columns='in_db', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roll_add.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(\"mssql+pyodbc:///?odbc_connect={}\".format(params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roll_add.to_sql('ca_roll', con=engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# roll_alter = roll0[roll0['exists_db'] == 1]\n",
    "# len(roll_alter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# roll_alter.drop(columns='exists_db', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# roll_alter['in_db'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#UPDATE SQL SERVER\n",
    "\n",
    "# main_alter.to_sql('temp_table', con=engine, if_exists='append', index=False)\n",
    "# main_alter.groupby('date_uploaded').sum()\n",
    "\n",
    "# sql = \"\"\"Update t1\n",
    "# SET t1.[license_adult] = t2.[license_adult], \n",
    "#     t1.[license_medicinal] = t2.[license_medicinal],\n",
    "#     t1.[license_annual] = t2.[license_annual],\n",
    "#     t1.[license_provisional] = t2.[license_provisional],\n",
    "#     t1.[date_issue] = t2.[date_issue],\n",
    "#     t1.[date_expiration] = t2.[date_expiration],\n",
    "#     t1.[status_active] = t2.[status_active],\n",
    "#     t1.[status_canceled] = t2.[status_canceled],\n",
    "#     t1.[status_expired] = t2.[status_expired],\n",
    "#     t1.[status_revoked] = t2.[status_revoked],\n",
    "#     t1.[status_surrendered] = t2.[status_surrendered],\n",
    "#     t1.[status_suspended] = t2.[status_suspended]\n",
    "# FROM [ca_cannabis].[dbo].[ca_main] as t1\n",
    "# INNER JOIN [ca_cannabis].[dbo].[temp_table] as t2\n",
    "# ON t1.[license_number] = t2.[license_number];\"\"\"\n",
    "\n",
    "# cnxn = pyodbc.connect(server = 'bespoke-database-1.cmevrozrcs7c.us-west-2.rds.amazonaws.com', \n",
    "#                       driver = '{ODBC Driver 17 for SQL Server}',\n",
    "#                       database = 'ca_cannabis',\n",
    "#                       UID = 'admin',\n",
    "#                       PWD = 'N19lrqxnurTUJLJT6GFe')\n",
    "\n",
    "# mycursor = cnxn.cursor()\n",
    "\n",
    "# mycursor.execute(sql)\n",
    "\n",
    "# sql = \"DELETE FROM temp_table\"\n",
    "\n",
    "# mycursor.execute(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#UPDATE SQL SERVER\n",
    "\n",
    "# contact_add.to_sql('temp_table_contact', con=engine, if_exists='append', index=False)\n",
    "\n",
    "# sql = \"\"\"Update t1\n",
    "# SET t1.[contact_email] = t2.[contact_email], \n",
    "# t1.[contact_phone] = t2.[contact_phone], \n",
    "# t1.[contact_website] = t2.[contact_website],\n",
    "# t1.[contact_owner_1] = t2.[contact_owner_1], \n",
    "# t1.[contact_owner_2] = t2.[contact_owner_2], \n",
    "# t1.[contact_street] = t2.[contact_street], \n",
    "# t1.[contact_city] = t2.[contact_city],\n",
    "# t1.[contact_county] = t2.[contact_county], \n",
    "# t1.[contact_state] = t2.[contact_state], \n",
    "# t1.[contact_zip] = t2.[contact_zip]\n",
    "# FROM [ca_cannabis].[dbo].[ca_contact] as t1\n",
    "# INNER JOIN [ca_cannabis].[dbo].[temp_table_contact] as t2\n",
    "# ON t1.[license_number] = t2.[license_number];\"\"\"\n",
    "\n",
    "# mycursor = cnxn.cursor()\n",
    "# mycursor.execute(sql)\n",
    "# sql = \"DELETE FROM temp_table\"\n",
    "# mycursor.execute(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CA CONTROL - address\n",
    "\n",
    "# df_add = df_file['premise_address'].str.split(',', expand=True)\n",
    "# df_zip_county = df_add[1].str.split('County:', expand=True)\n",
    "# df_street = df_add[0]\n",
    "# df_zip_county[0] = df_zip_county[0].str.replace(\"CA\", \"\")\n",
    "# df_zip_county[0] = df_zip_county[0].str.strip()\n",
    "# df_zip_county[1] = df_zip_county[1].str.strip()\n",
    "# df_zip_county[1] = df_zip_county[1].str.lower()\n",
    "# df_zip_county[0] = df_zip_county[0].str[:5]\n",
    "# df_zip_county.rename(columns={0: 'contact_zip', 1: 'contact_county'}, inplace=True)\n",
    "# df_zip_county['contact_state'] = 'CA'\n",
    "# pd_zip_county = pd.concat([df_street, df_zip_county], axis=1)\n",
    "# pd_zip_county.rename(columns={0:'contact_street'}, inplace=True)\n",
    "# pd_zip_county['contact_street'] = pd_zip_county['contact_street'].str.lower()\n",
    "# pd_zip_county['contact_street'] = pd_zip_county['contact_street'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cnxn = pyodbc.connect(server = 'bespoke-database-1.cmevrozrcs7c.us-west-2.rds.amazonaws.com', \n",
    "#                       driver = '{ODBC Driver 17 for SQL Server}',\n",
    "#                       database = 'ca_cannabis',\n",
    "#                       UID = 'admin',\n",
    "#                       PWD = 'N19lrqxnurTUJLJT6GFe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cnxn = pyodbc.connect('Trusted_Connection=yes',\n",
    "#                       server = 'DESKTOP-KA6KCMH\\SQLEXPRESS', \n",
    "#                       driver = '{ODBC Driver 17 for SQL Server}',\n",
    "#                       database = 'ca_cannabis_v3'\n",
    "#                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#i think this is more useful when i was only doing a subset of the control file and not the entirety.\n",
    "# df2[~df2[5].isnull()]\n",
    "#I dont know what this does. renames the column headers I think if need to remove columns\n",
    "# df2 = df2.reindex(columns=range(len(df_names_removed.columns)))\n",
    "#again not sure the point\n",
    "# df2.columns = df_names_removed.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_file[df_file.duplicated()]\n",
    "#only need to do if there are duplicates\n",
    "\n",
    "# df_file.drop_duplicates(subset='license_number', keep='first', inplace=True)\n",
    "# df_file.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_file_m[df_file_m.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cult_biz = pd.read_csv('./cultivation_files/Annual_ Provisional Business 2020_03_12.csv')\n",
    "# cult_drp = pd.read_csv('./cultivation_files/Annual_Provisional DRP 2020_03_12.csv')\n",
    "# cult_df = cult_biz.append(cult_drp, sort=False)\n",
    "# cult_df[cult_df['License Number'] == 'License Number']\n",
    "# cult_df.drop_duplicates(subset='License Number', keep='first', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_new_items.drop(columns=['status','in_db'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_all = pd.read_csv('./df_all_v10.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_all['date_issue'] = pd.to_datetime(df_all['date_issue'], format=\"%m/%d/%Y\")\n",
    "# df_all['date_expiration'] = pd.to_datetime(df_all['date_expiration'], format=\"%m/%d/%Y\")\n",
    "# df_all['date_uploaded'] = pd.to_datetime(df_all['date_uploaded'], format=\"%m/%d/%Y\")\n",
    "\n",
    "# df_all['status_inactive'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_name_legal_null = df_all[df_all['name_legal'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check to see if df_roll has any blank name_legal. if so delete. \n",
    "# keep blanks to assign them a roll up id and company name if possible.\n",
    "\n",
    "# df_roll[df_roll['company_roll_up'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to remove blanks or when you merge on name legal it creates a bunch of duplicates\n",
    "# df_all.drop(df_all[df_all['name_legal'].isnull()].index, inplace=True)\n",
    "# df_all.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_final.rename(columns={'changed_contact_info?': 'changed_contact_info'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main_drop[main_drop.duplicated(subset='license_number')]\n",
    "# main_drop[main_drop['license_number'] == 'CCL18-0001395']\n",
    "# sql_dupe = sql_main[sql_main.duplicated(subset='license_number')]\n",
    "# sql_main[sql_main['license_number'] == 'CCL18-0001395']\n",
    "# sql_main[sql_main.duplicated(subset='license_number')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# engine = create_engine('mssql+pyodbc://DESKTOP-KA6KCMH\\SQLEXPRESS/ca_cannabis_v3?driver=ODBC Driver 17 for SQL Server')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# contact_drop_v1 = contact_all.drop_duplicates(subset=['license_number', 'contact_email', 'contact_phone', 'contact_website',\n",
    "#        'contact_owner_1', 'contact_owner_2', 'contact_street', 'contact_city',\n",
    "#        'contact_county', 'contact_state', 'contact_zip'], keep='first')\n",
    "\n",
    "# contact_drop_v1[contact_drop_v1.duplicated(subset='license_number')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sql_main = pd.read_sql(\"SELECT * FROM ca_main\", cnxn)\n",
    "# sql_contact = pd.read_sql(\"SELECT * FROM ca_contact\", cnxn)\n",
    "# sql_roll = pd.read_sql(\"SELECT * FROM ca_roll\", cnxn)\n",
    "# sql_main.to_excel('./sql_main_20200331.xlsx', index=False)\n",
    "# sql_contact.to_excel('./sql_contact_20200331.xlsx', index=False)\n",
    "# sql_roll.to_excel('./sql_roll_20200331.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# roll_all.isnull()\n",
    "# roll_all.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main_drop = main_drop.append(main_change_0)\n",
    "# main_drop.drop_duplicates(subset='license_number', keep='last')\n",
    "# main_drop[main_drop['license_number'] == 'CCL18-0000011']\n",
    "# main_drop.iloc[463] == main_drop.iloc[9046]\n",
    "# main_drop['name_dba'].iloc[9628] == 0\n",
    "# main_drop['name_dba'].iloc[2146]\n",
    "# main_drop[main_drop['name_dba'] == '0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main_drop[main_drop['name_dba'] == '0']\n",
    "# main_drop['name_dba'].iloc[2] == '0'\n",
    "\n",
    "# main_change_0 = main_drop[main_drop['name_dba'] == '0']\n",
    "# main_drop['lic'] == 0\n",
    "#122 = '0'\n",
    "#7187 = 0\n",
    "# main_change_0['name_dba'] = 0\n",
    "# main_change_0['name_dba'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sql_main.fillna(0, inplace=True)\n",
    "# df_main.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_name_legal_null = df_all[(df_all['name_legal'] == \"\") | (df_all['name_legal'].isnull())]\n",
    "# len(df_name_legal_null)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 'license_number', \n",
    "# 'license_category', \n",
    "# 'license_description',\n",
    "# 'license_adult', \n",
    "# 'license_medicinal', \n",
    "# 'license_annual',\n",
    "# 'license_provisional', \n",
    "# 'name_legal', \n",
    "# 'name_dba', \n",
    "# 'name_legal_clean',\n",
    "# 'roll_up_id', \n",
    "# 'company_roll_up', \n",
    "# 'date_issue', \n",
    "# 'date_expiration',\n",
    "# 'status_active', \n",
    "# 'status_canceled', \n",
    "# 'status_expired', \n",
    "# 'status_inactive',\n",
    "# 'status_revoked', \n",
    "# 'status_surrendered', \n",
    "# 'status_suspended',\n",
    "# 'business_description', \n",
    "# 'business_company_type', \n",
    "# 'contact_email', \n",
    "# 'contact_phone',\n",
    "# 'contact_website',\n",
    "# 'contact_owner_1', \n",
    "# 'contact_owner_2',\n",
    "# 'contact_street',\n",
    "# 'contact_city',\n",
    "# 'contact_county', \n",
    "# 'contact_state',\n",
    "# 'contact_zip',\n",
    "# 'changed_contact_info',\n",
    "# 'date_uploaded', \n",
    "# 'in_db' #36 total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_final_add['date_uploaded'] = pd.datetime(2020, 4,29)\n",
    "\n",
    "# df_final_add['in_db'] = 0\n",
    "\n",
    "# df_sql_merge.drop(columns=['roll_up_id', 'company_roll_up'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sql = \"\"\"Update t1\n",
    "# SET t1.[name_legal] = t2.[name_legal],\n",
    "#     t1.[name_dba] = t2.[name_dba],\n",
    "#     t1.[license_adult] = t2.[license_adult], \n",
    "#     t1.[license_medicinal] = t2.[license_medicinal],\n",
    "#     t1.[license_annual] = t2.[license_annual],\n",
    "#     t1.[license_provisional] = t2.[license_provisional],\n",
    "#     t1.[date_issue] = t2.[date_issue],\n",
    "#     t1.[date_expiration] = t2.[date_expiration],\n",
    "#     t1.[status_active] = t2.[status_active],\n",
    "#     t1.[status_canceled] = t2.[status_canceled],\n",
    "#     t1.[status_expired] = t2.[status_expired],\n",
    "#     t1.[status_revoked] = t2.[status_revoked],\n",
    "#     t1.[status_surrendered] = t2.[status_surrendered],\n",
    "#     t1.[status_suspended] = t2.[status_suspended]\n",
    "# FROM [ca_cannabis].[dbo].[ca_main] as t1\n",
    "# INNER JOIN [ca_cannabis].[dbo].[temp_table] as t2\n",
    "# ON t1.[license_number] = t2.[license_number];\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main_alter['date_uploaded'] = pd.to_datetime(main_alter['date_uploaded'], format=\"%m/%d/%Y\")\n",
    "# main_alter.columns\n",
    "# main_alter.iloc[:,[0,1,2,4,5,6,7,9,10,11,12,13,14,15,16]]\n",
    "# main_drop[main_drop['license_number'] == 'CCL18-0001771'].iloc[:,[1,2,4,5,6,7,9,10,11,12,13,14,15,16]]\n",
    "# main_drop.iloc[9138]\n",
    "# main_drop.iloc[7278] == main_drop.iloc[10293]\n",
    "# main_alter.iloc[0]\n",
    "# main_drop[main_drop['license_number'] == 'CCL19-0000084']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_main[df_main['license_number'] == 'CCL19-0001283']\n",
    "# sql_main[sql_main['license_number'] == 'CCL19-0001283']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_sql_merge[['license_number', 'license_category', 'license_description',\n",
    "#        'license_adult', 'license_medicinal', 'license_annual',\n",
    "#        'license_provisional', \n",
    "#         'name_legal', 'name_dba', 'name_legal_clean',\n",
    "#        'roll_up_id', 'company_roll_up', \n",
    "#         'date_issue', 'date_expiration',\n",
    "#        'status_active', 'status_canceled', 'status_expired', 'status_inactive',\n",
    "#        'status_revoked', 'status_surrendered', 'status_suspended',    \n",
    "#        'business_description', 'business_company_type', \n",
    "#         'company_roll_up','roll_up_id', \n",
    "#         'changed_contact_info', 'date_uploaded', 'in_db','in_sql', \n",
    "#         'contact_email', 'contact_phone', 'contact_website',\n",
    "#        'contact_owner_1', 'contact_owner_2', 'contact_street', 'contact_city',\n",
    "#        'contact_county', 'contact_state', 'contact_zip']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_final_add[['license_number', 'license_category', 'license_description',\n",
    "#        'license_adult', 'license_medicinal', 'license_annual',\n",
    "#        'license_provisional', \n",
    "#         'name_legal', 'name_dba', 'name_legal_clean',\n",
    "#         'roll_up_id', 'company_roll_up',      \n",
    "#         'date_issue', 'date_expiration', \n",
    "#         'status_active', 'status_canceled', 'status_expired', 'status_inactive', \n",
    "#         'status_revoked', 'status_surrendered','status_suspended', \n",
    "#         'business_description', 'business_company_type',\n",
    "#        'contact_email', 'contact_phone', 'contact_website', 'contact_owner_1',\n",
    "#        'contact_owner_2', 'contact_street', 'contact_city', 'contact_county',\n",
    "#        'contact_state', 'contact_zip', 'date_uploaded', 'in_db',\n",
    "        \n",
    "#        'changed_contact_info', 'in_sql']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_edited['roll_up_id'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_sql_merge.append(df_final_add, sort=False)\n",
    "# df_sql_merge['in_sql'] = 1\n",
    "# df_to_edit.columns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
