{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from functools import reduce\n",
    "import pyodbc\n",
    "from sqlalchemy import create_engine\n",
    "import urllib\n",
    "from datetime import date\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnxn = pyodbc.connect(server = 'bespoke-database-1.cmevrozrcs7c.us-west-2.rds.amazonaws.com', \n",
    "                      driver = '{ODBC Driver 17 for SQL Server}',\n",
    "                      database = 'ca_cannabis',\n",
    "                      UID = 'admin',\n",
    "                      PWD = 'N19lrqxnurTUJLJT6GFe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_roll = pd.read_sql(\"SELECT * FROM ca_roll\", cnxn)\n",
    "len(df_roll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = Path('../ar_reports/orig/no_neg').glob('*.csv')\n",
    "list_of_dfs = [pd.read_csv(file) for file in filenames]\n",
    "for dataframe, file in zip(list_of_dfs, filenames):\n",
    "    Dataframe['file'] = file\n",
    "df_file = pd.concat(list_of_dfs, ignore_index=True, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_file['date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_file.to_csv('../credit_score_files/df_file_10_05_20.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_file['date'] = pd.to_datetime(df_file['date'], format=\"%m/%d/%Y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ar = df_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ar.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "merge AR report on license number with roll_up id df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ar['license_number'] = df_ar['license_number'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ar_roll = pd.merge(df_ar, df_roll, on='license_number', how='left')\n",
    "df_ar_roll.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "number of accounts still missing roll up id after above merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_ar_roll[df_ar_roll['roll_up_id'].isnull()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "split out the ones where roll up id is filled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ar_roll_fill = df_ar_roll[~df_ar_roll['roll_up_id'].isnull()]\n",
    "len(df_ar_roll_fill)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### includes companies where license number is NOT populated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ar_roll.to_csv('../credit_score_files/combined_lists_include_nulls_2020_12_17.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### only includes companies where license number IS populated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ar_roll_fill.to_csv('../credit_score_files/combined_lists_2020_12_17.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = df_ar_roll_fill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.to_csv('../credit_score_files/credit_score_2020_12_21.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## code for credit database stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_bal = df_all.groupby(by='client')['bal_out'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_bal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_bal.to_csv('../credit_score_files/client_balances_2020_12_17.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(df_all['license_number'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(df_all['roll_up_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ar_final.groupby(['ar_account', 'date'], as_index=False)['days_over_due'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_count = df_all.groupby('client', as_index=True)['license_number'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_nunique = df_all.groupby('client', as_index=True)['license_number'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_unique_roll = df_all.groupby('client', as_index=True)['roll_up_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_count.rename('license_count', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_all_count = pd.concat([df_count, df_nunique, df_unique_roll], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_all_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_all_count.to_csv('../credit_score_files/df_all_count_10_05_20.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_count.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_nunique.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_unique_roll.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# client_max_date = df_all[['client', 'date']].groupby('client', as_index=False).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# client_max_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(df_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(df_all['license_number'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(df_all['roll_up_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_all['bal_out'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credit score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "determine which month has the most outstanding / count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_all.groupby(by='date').sum()['bal_out'].apply(\"{:,.10}\".format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_all.groupby(by='date').count()['license_number']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "month to use for analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "can use the below to add together all historical and then do another one based on recent month. only grab historical that match most recent month (maybe use 3/31 as it has more?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_rct = df_all[(df_all['date'] <= pd.Timestamp(date(2020,3,31))) & (df_all['date'] >= pd.Timestamp(date(2020,3,16)))]\n",
    "# df_rct = df_all[df_all['date'] == pd.Timestamp(date(2020, 4, 10))]\n",
    "# df_rct = df_all[(df_all['date'] <= pd.Timestamp(date(2020,3,31))) & (df_all['date'] >= pd.Timestamp(date(2020,3,16)))]\n",
    "# df_rct = df_all_recent[df_all_recent['date'] >= pd.Timestamp(date(2020,1,1))]\n",
    "# df_rct = df_all[df_all['date'] <= pd.Timestamp(date(2020, 5, 31))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(df_rct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# client_max_date.merge(df_all, on=['client', 'date'], how='left').sort_values(by='client', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_all_recent = client_max_date.merge(df_all, on=['client', 'date'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_all_recent = client_max_date.merge(df_all, on=['client', 'date'], how='right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_all_recent.to_csv('../credit_score_files/df_all_recent_09_03_v6.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_rct.groupby('date').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_rct = df_all_recent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_groupby = df_rct.groupby('roll_up_id', as_index=False)['license_number'].count()\n",
    "sum_payors = df_rct.groupby('roll_up_id', as_index=False)['count_payor'].sum()\n",
    "sum_days_over = df_rct.groupby('roll_up_id', as_index=False)['sum_days_over'].sum()\n",
    "sum_orig_amt = df_rct.groupby('roll_up_id', as_index=False)['orig_amt'].sum()\n",
    "sum_bal_out = df_rct.groupby('roll_up_id', as_index=False)['bal_out'].sum()\n",
    "sum_current = df_rct.groupby('roll_up_id', as_index=False)['current'].sum()\n",
    "sum_30_day = df_rct.groupby('roll_up_id', as_index=False)['30_days'].sum()\n",
    "sum_60_day = df_rct.groupby('roll_up_id', as_index=False)['60_days'].sum()\n",
    "sum_90_day = df_rct.groupby('roll_up_id', as_index=False)['90_days'].sum()\n",
    "sum_over_90 = df_rct.groupby('roll_up_id', as_index=False)['over_90_days'].sum()\n",
    "sum_delinq = df_rct.groupby('roll_up_id', as_index=False)['delinquent'].sum()\n",
    "sum_sum = df_rct.groupby('roll_up_id', as_index=False)['summary'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frames = [count_groupby, sum_payors, sum_days_over, sum_orig_amt, sum_bal_out, sum_current, sum_30_day,\n",
    "               sum_60_day, sum_90_day, sum_over_90, sum_delinq, sum_sum]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rct_sums = reduce(lambda left,right: pd.merge(left,right,on=['roll_up_id'], how='outer'), data_frames)\n",
    "len(df_rct_sums)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "remove if under 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rct_bal = df_rct_sums[df_rct_sums['bal_out'] > 500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('mode.chained_assignment', None)\n",
    "\n",
    "list_curr = df_rct_bal[(df_rct_bal['current'] < 500) & (df_rct_bal['current'] > 0)].index\n",
    "df_rct_bal['current'].loc[list_curr] = 0\n",
    "\n",
    "list_30 = df_rct_bal[(df_rct_bal['30_days'] < 500) & (df_rct_bal['30_days'] > 0)].index\n",
    "df_rct_bal['30_days'].loc[list_30] = 0\n",
    "\n",
    "list_60 = df_rct_bal[(df_rct_bal['60_days'] < 500) & (df_rct_bal['60_days'] > 0)].index\n",
    "df_rct_bal['60_days'].loc[list_60] = 0\n",
    "\n",
    "list_90 = df_rct_bal[(df_rct_bal['90_days'] < 500) & (df_rct_bal['90_days'] > 0)].index\n",
    "df_rct_bal['90_days'].loc[list_90] = 0\n",
    "\n",
    "list_ovr_90 = df_rct_bal[(df_rct_bal['over_90_days'] < 500) & (df_rct_bal['over_90_days'] > 0)].index\n",
    "df_rct_bal['over_90_days'].loc[list_ovr_90] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rct_bal.drop(columns='bal_out', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "recalculate the balance outstanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('mode.chained_assignment', None)\n",
    "\n",
    "df_rct_bal['bal_out'] = df_rct_bal['current'] + df_rct_bal['30_days'] + df_rct_bal['60_days'] + df_rct_bal['90_days'] + df_rct_bal['over_90_days']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_rct_bal = df_rct_bal[['roll_up_id', 'bal_out', 'current', '30_days', '60_days', '90_days', 'over_90_days', 'delinquent']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_rct_bal[df_rct_bal['bal_out'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(df_rct_bal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(df_rct_bal[df_rct_bal['bal_out'] != 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_rct_bal = df_rct_bal[df_rct_bal['bal_out'] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_rct_bal[df_rct_bal['times_total'] < 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "count if DPD over 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('mode.chained_assignment', None)\n",
    "\n",
    "df_rct_bal['count_curr'] = df_rct_bal['current'].apply(lambda x: 0 if x == 0 else 1)\n",
    "df_rct_bal['count_30'] = df_rct_bal['30_days'].apply(lambda x: 0 if x == 0 else 1)\n",
    "df_rct_bal['count_60'] = df_rct_bal['60_days'].apply(lambda x: 0 if x == 0 else 1)\n",
    "df_rct_bal['count_90'] = df_rct_bal['90_days'].apply(lambda x: 0 if x == 0 else 1)\n",
    "df_rct_bal['count_ovr_90'] = df_rct_bal['over_90_days'].apply(lambda x: 0 if x == 0 else 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "apply a score for each count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rct_bal['score_curr'] = df_rct_bal['count_curr'].apply(lambda x: 0 if x == 0 else 2)\n",
    "df_rct_bal['score_30'] = df_rct_bal['count_30'].apply(lambda x: 0 if x == 0 else 4)\n",
    "df_rct_bal['score_60'] = df_rct_bal['count_60'].apply(lambda x: 0 if x == 0 else 8)\n",
    "df_rct_bal['score_90'] = df_rct_bal['count_90'].apply(lambda x: 0 if x == 0 else 16)\n",
    "df_rct_bal['score_ovr_90'] = df_rct_bal['count_ovr_90'].apply(lambda x: 0 if x == 0 else 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rct_bal['score_total'] = df_rct_bal['score_curr'] + df_rct_bal['score_30'] + df_rct_bal['score_60'] + df_rct_bal['score_90'] + df_rct_bal['score_ovr_90']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "% of DPD over balance outstanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rct_bal['pct_curr'] = df_rct_bal['current'] / df_rct_bal['bal_out']\n",
    "df_rct_bal['pct_30'] = df_rct_bal['30_days'] / df_rct_bal['bal_out']\n",
    "df_rct_bal['pct_60'] = df_rct_bal['60_days'] / df_rct_bal['bal_out']\n",
    "df_rct_bal['pct_90'] = df_rct_bal['90_days'] / df_rct_bal['bal_out']\n",
    "df_rct_bal['pct_ovr_90'] = df_rct_bal['over_90_days'] / df_rct_bal['bal_out']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "multiply score by % of DPD over outstanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rct_bal['times_curr'] = df_rct_bal['score_curr'] * df_rct_bal['pct_curr']\n",
    "df_rct_bal['times_30'] = df_rct_bal['score_30'] * df_rct_bal['pct_30']\n",
    "df_rct_bal['times_60'] = df_rct_bal['score_60'] * df_rct_bal['pct_60']\n",
    "df_rct_bal['times_90'] = df_rct_bal['score_90'] * df_rct_bal['pct_90']\n",
    "df_rct_bal['times_ovr_90'] = df_rct_bal['score_ovr_90'] * df_rct_bal['pct_ovr_90']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rct_bal['times_total'] = df_rct_bal['times_curr'] + df_rct_bal['times_30'] + df_rct_bal['times_60'] + df_rct_bal['times_90'] + df_rct_bal['times_ovr_90'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get unique id from roll up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_roll_edit = df_roll[['roll_up_id', 'company_roll_up']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('mode.chained_assignment', None)\n",
    "\n",
    "df_roll_edit.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = df_rct_bal.merge(df_roll_edit, on='roll_up_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final['score_total'].quantile([0, 0.25, 0.5, 0.75, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final['times_total'].quantile([0, 0.25, 0.5, 0.75, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final['quant_score'] = pd.qcut(df_final['score_total'], 4, labels=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final['quant_times'] = pd.qcut(df_final['times_total'], 4, labels=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = df_final[['roll_up_id', 'company_roll_up', 'bal_out', 'current', '30_days', '60_days', '90_days',\n",
    "       'over_90_days', 'delinquent', \n",
    "        'count_curr', 'count_30', 'count_60','count_90', 'count_ovr_90', \n",
    "        'score_curr', 'score_30', 'score_60','score_90', 'score_ovr_90', 'score_total', \n",
    "                     'quant_score', \n",
    "        'pct_curr', 'pct_30', 'pct_60', 'pct_90', 'pct_ovr_90', \n",
    "        'times_curr', 'times_30', 'times_60','times_90', 'times_ovr_90', 'times_total','quant_times']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_final[df_final['roll_up_id'] == 3029]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_final[df_final['company_roll_up'] == 'haute supply']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.to_csv('../credit_score_files/credit_score_2020_09_03_v6.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2020_Q2 = df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2020_Q1 = df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2019_Q4 = df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_2019_09_30 = df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2019_Q3 = df_2019_09_30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_2019_06_30 = df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2019_Q2 = df_2019_06_30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_2019_03_31 = df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2019_Q1 = df_2019_03_31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_2019_06_30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(df_final)\n",
    "#372"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_final[df_final['delinquent'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2019_Q1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2019_Q1_edit = df_2019_Q1[['roll_up_id', \n",
    "                            'company_roll_up', \n",
    "                            'bal_out', 'current', '30_days',\n",
    "                            '60_days', '90_days', 'over_90_days', 'delinquent', \n",
    "                            'score_total','quant_score', \n",
    "                            'times_total', 'quant_times']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## roll up analysis historical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_groupby = df_all.groupby('roll_up_id', as_index=False)['license_number'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_payors = df_all.groupby('roll_up_id', as_index=False)['count_payor'].sum()\n",
    "sum_days_over = df_all.groupby('roll_up_id', as_index=False)['sum_days_over'].sum()\n",
    "sum_orig_amt = df_all.groupby('roll_up_id', as_index=False)['orig_amt'].sum()\n",
    "sum_bal_out = df_all.groupby('roll_up_id', as_index=False)['bal_out'].sum()\n",
    "sum_current = df_all.groupby('roll_up_id', as_index=False)['current'].sum()\n",
    "sum_30_day = df_all.groupby('roll_up_id', as_index=False)['30_days'].sum()\n",
    "sum_60_day = df_all.groupby('roll_up_id', as_index=False)['60_days'].sum()\n",
    "sum_90_day = df_all.groupby('roll_up_id', as_index=False)['90_days'].sum()\n",
    "sum_over_90 = df_all.groupby('roll_up_id', as_index=False)['over_90_days'].sum()\n",
    "sum_delinq = df_all.groupby('roll_up_id', as_index=False)['delinquent'].sum()\n",
    "sum_sum = df_all.groupby('roll_up_id', as_index=False)['summary'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count_groupby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frames = [count_groupby, sum_payors, sum_days_over, sum_orig_amt, sum_bal_out, sum_current, sum_30_day,\n",
    "               sum_60_day, sum_90_day, sum_over_90, sum_delinq, sum_sum]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sums = reduce(lambda left,right: pd.merge(left,right,on=['roll_up_id'], how='left'), data_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sums['pct_curr'] = df_sums['current'] / df_sums['bal_out']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sums['pct_30'] = df_sums['30_days'] / df_sums['bal_out']\n",
    "df_sums['pct_60'] = df_sums['60_days'] / df_sums['bal_out']\n",
    "df_sums['pct_90'] = df_sums['90_days'] / df_sums['bal_out']\n",
    "df_sums['pct_ovr_90'] = df_sums['over_90_days'] / df_sums['bal_out']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sums.fillna(value=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sums.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_sums[df_sums['bal_out'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sums_bal = df_sums[df_sums['bal_out'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_sums_bal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_sums_bal['orig_amt'].quantile([0.1,0.2,0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sums_bal['bal_out'].quantile([0.1,0.2,0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_sums_bal['bal_quant'] = pd.qcut(df_sums_bal['bal_out'], 10, labels=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_sums_bal.groupby('bal_quant').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.qcut(df_sums_bal['pct_curr'], 3, labels=False)\n",
    "# pd.qcut(df_sums_bal['pct_30'], 3, labels=False)\n",
    "# pd.qcut(df_sums_bal['sum_60_quant'], 4, labels=False)\n",
    "# pd.qcut(df_sums_bal['sum_90'], 4, labels=False)\n",
    "# pd.qcut(df_sums_bal['sum_ovr_90'], 2, labels=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sums_bal.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sums_bal.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_sums_bal.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sums_bal.iloc[:2, 22:27]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_sums_bal.iloc[:,14:19].apply(lambda x: pd.Series([(x < 0).sum()]), axis=1)\n",
    "# train_test.iloc[:,[6,15]].apply(lambda x: \n",
    "#                           0 if (x.loc['past_due_60'] > 95) \n",
    "#                           else x, axis=1)\n",
    "\n",
    "df_sums_bal['count_curr'] = df_sums_bal.iloc[:,6].apply(lambda x: 0 if x == 0 else 1)\n",
    "df_sums_bal['count_30'] = df_sums_bal.iloc[:,7].apply(lambda x: 0 if x == 0 else 1)\n",
    "df_sums_bal['count_60'] = df_sums_bal.iloc[:,8].apply(lambda x: 0 if x == 0 else 1)\n",
    "df_sums_bal['count_90'] = df_sums_bal.iloc[:,9].apply(lambda x: 0 if x == 0 else 1)\n",
    "df_sums_bal['count_ovr_90'] = df_sums_bal.iloc[:,10].apply(lambda x: 0 if x == 0 else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sums_bal['score_curr'] = df_sums_bal.iloc[:,22].apply(lambda x: 0 if x == 0 else 2)\n",
    "df_sums_bal['score_30'] = df_sums_bal.iloc[:,23].apply(lambda x: 0 if x == 0 else 4)\n",
    "df_sums_bal['score_60'] = df_sums_bal.iloc[:,24].apply(lambda x: 0 if x == 0 else 6)\n",
    "df_sums_bal['score_90'] = df_sums_bal.iloc[:,25].apply(lambda x: 0 if x == 0 else 8)\n",
    "df_sums_bal['score_ovr_90'] = df_sums_bal.iloc[:,26].apply(lambda x: 0 if x == 0 else 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_sums_bal.drop(columns=['count_curr', 'count_30', 'count_60', 'count_90', 'count_ovr_90', 'score_curr', 'score_30', 'score_60', 'score_90', 'score_ovr_90'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_sums_bal.drop(columns='score_total', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_sums_bal.iloc[:,22]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sums_bal.iloc[:5, 6:11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sums_bal.iloc[:5, 22:27]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sums_bal.to_csv('../ar_reports/df_sums_bal_04_29.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sums_bal.iloc[:20, 6:11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sums_bal.iloc[:20, 22:33]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feb_bal['score_total'].quantile([0.25, 0.5, 0.75])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sums_bal['score_total'].quantile(q=[0.25, 0.5, 0.75])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sums_bal['score_total'] = df_sums_bal['score_curr'] + df_sums_bal['score_30'] + df_sums_bal['score_60'] + df_sums_bal['score_90'] + df_sums_bal['score_ovr_90']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.qcut(df_sums_bal['score_total'], 4, labels=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sums_bal.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sums_bal['sum_30'] = df_sums_bal['pct_curr'] + df_sums_bal['pct_30']\n",
    "df_sums_bal['sum_60'] = df_sums_bal['pct_curr'] + df_sums_bal['pct_30'] + df_sums_bal['pct_60']\n",
    "df_sums_bal['sum_90'] = df_sums_bal['pct_curr'] + df_sums_bal['pct_30'] + df_sums_bal['pct_60'] + df_sums_bal['pct_90']\n",
    "df_sums_bal['sum_ovr_90'] = df_sums_bal['pct_curr'] + df_sums_bal['pct_30'] + df_sums_bal['pct_60'] + df_sums_bal['pct_90'] + df_sums_bal['pct_ovr_90']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_sums_bal.drop(columns='sum_60', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_sums_bal.rename(columns={'sum_60_quant': 'sum_60'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sums_bal['sum_ovr_90'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sums_bal['over_90_days'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.qcut(df_sums_bal['60_days'], 2, labels=False)\n",
    "# pd.qcut(df_sums_bal['60_days'], 1, labels=False)\n",
    "# df_sums_bal['curr_quant'] = pd.qcut(df_sums_bal['current'], 2, labels=False)\n",
    "# df_sums_bal['30_quant'] = pd.qcut(df_sums_bal['30_days'], 2, labels=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.set_option('mode.chained_assignment', None)\n",
    "\n",
    "# # df_sums_bal['bal_quant'] = pd.qcut(df_sums_bal['bal_out'], 10, labels=False)\n",
    "# # df_sums_bal['curr_quant'] = pd.qcut(df_sums_bal['current'], 10, labels=False)\n",
    "# # df_sums_bal['30_quant'] = pd.qcut(df_sums_bal['30_days'], 10, labels=False)\n",
    "# df_sums_bal['60_quant'] = pd.qcut(df_sums_bal['60_days'], 10, labels=False)\n",
    "# df_sums_bal['90_quant'] = pd.qcut(df_sums_bal['90_days'], 10, labels=False)\n",
    "# df_sums_bal['ovr_90_quant'] = pd.qcut(df_sums_bal['over_90_days'], 10, labels=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(df_sums_bal['bal_out'])):\n",
    "#     print(df_sums_bal['bal_out'].iloc[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sums_bal['pct_curr'].qcut()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_sums_bal['over_90_days'].quantile(q=[.25, .5, .75])\n",
    "df_sums_bal['over_90_days'].quantile(q=[0,.5,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sums_bal['over_90_days'].quantile([0.1,0.2,0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sums_bal['pct_30'].quantile([0.1,0.2,0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sums_bal['pct_60'].quantile([0.1,0.2,0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sums_bal['pct_90'].quantile([0.1,0.2,0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sums_bal['pct_ovr_90'].quantile([0.1,0.2,0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_all.groupby(by='roll_up_id').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_group_sum = df_all.groupby(by='roll_up_id').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_all.rename(columns={'license provided': 'license_provided'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_all_group_sum.rename(columns={'license provided': 'license_provided'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_group = df_all_group_sum[['license_provided', 'count_payor', 'sum_days_over', 'orig_amt', 'bal_out',\n",
    "                 'current', '30_days', '60_days', '90_days', 'over_90_days', 'delinquent', 'summary']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_group_bal = df_group[df_group['bal_out'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_roll.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_roll_cut = df_roll[['roll_up_id', 'company_roll_up']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_roll_cut = df_roll_cut.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_group_bal.merge(df_roll_cut, on='roll_up_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.time_diff.quantile([0.25,0.5,0.75])\n",
    "df_group_bal['30_days'].quantile([0.25,0.5,0.75])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['60_days'].quantile([0.25,0.5,0.75])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['90_days'].quantile([0.25,0.5,0.75])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_all.to_csv('../ar_reports/kiva_sql_combined.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_all = pd.read_csv('../ar_reports/kiva_sql_combined.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://towardsdatascience.com/train-test-split-and-cross-validation-in-python-80b61beca4b6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "9/413"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['delinquent'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_all['delinquent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to split out the columns that are numeric to use for train / test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "\n",
    "new_df = df_all.select_dtypes(include=numerics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.drop(columns=['delinquent', 'roll_up_id', 'in_db', 'contact_phone', 'contact_zip'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.fillna(value=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_all.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(new_df, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = linear_model.LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = lm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "sns.heatmap(train.corr(), annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_corr = train.corr()\n",
    "plt.figure(figsize=(10,10))\n",
    "sns.heatmap(train_corr[['SeriousDlqin2yrs']].sort_values(by=['SeriousDlqin2yrs'], ascending=False), vmin=-1, vmax=1, annot=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(train['NumberOfTimes90DaysLate']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.groupby('NumberOfTimes90DaysLate').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_ar = pd.read_sql(\"SELECT * FROM ar_report\", cnxn)\n",
    "# len(df_ar)\n",
    "\n",
    "# ar.to_csv('../ar_reports/humboldt_ar_clean_04_23_20.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_main = pd.read_sql(\"SELECT * FROM ca_main\", cnxn)\n",
    "# len(df_main)\n",
    "\n",
    "# df_contact = pd.read_sql(\"SELECT * FROM ca_contact\", cnxn)\n",
    "# len(df_contact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_ar_main = pd.merge(df_ar_roll_fill, df_main, on='license_number', how='left')\n",
    "# df_all = pd.merge(df_ar_main, df_contact, on='license_number', how='left')\n",
    "\n",
    "# df_all.to_csv('../ar_reports/ar_kiva_hf_sql_detail_v2.csv', index=False)\n",
    "\n",
    "# df_all = pd.read_csv('../ar_reports/ar_kiva_hf_sql_detail_v2.csv')\n",
    "\n",
    "# df_all[['current']]\n",
    "# df_summary = df_all[df_all['summary'] == 0]\n",
    "# df_sum_0 = df_summary[df_summary['bal_out'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import seaborn as sns\n",
    "# df_sum_0[df_sum_0['current'] > 0]['current']\n",
    "# sns.distplot(df_sum_0['current'])\n",
    "# import matplotlib.pyplot as plt\n",
    "# df_sum_0['current'].\n",
    "# format(df_sum_0[df_sum_0['current'] > 0]['current'], \",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(12,6))\n",
    "# x = df_sum_0[df_sum_0['current'] > 0]['current']\n",
    "# ax = sns.distplot(x)\n",
    "\n",
    "# # ax.get_xaxis().set_major_formatter(plt.ticker.FuncFormatter(lambda x, p: format(int(x), ',')))\n",
    "\n",
    "# ax.get_xaxis().set_major_formatter(plt.FuncFormatter(lambda x, loc: \"{:,}\".format(int(x))))\n",
    "\n",
    "# xlabels = ['{:,.2f}'.format(x) for x in g.get_xticks()/1000]\n",
    "# g.set_xticklabels(xlabels)\n",
    "\n",
    "# sns.set(); np.random.seed(0)\n",
    "# x = np.random.randn(100)\n",
    "# ax = sns.distplot(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_ar_roll['license_number'].iloc[1]\n",
    "# df_ar_roll['license_number'].str.strip()\n",
    "# df_ar_roll[df_ar_roll['roll_up_id'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_all['30_days'].sum()\n",
    "# df_all['current'].quantile([0.25,0.5,0.75])\n",
    "# df_all['current'].median()\n",
    "# df_all.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_all.to_csv('../ar_reports/ar_combined_04_29.csv', index=False)\n",
    "# df_ar = pd.read_csv('../ar_reports/kiva_hr_ar_combined.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_feb_bal.rename(columns={'total':'bal_out'}, inplace=True)\n",
    "# df_feb_bal[df_feb_bal['bal_out'] != df_feb_bal['total']]\n",
    "# df_feb_bal['current'].apply(lambda x: 0 if x == 0 else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_rct_bal.columns.get_loc(\"times_total\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_rct_sums[df_rct_sums['delinquent'] > 0]\n",
    "# df_feb_bal = df_feb_sums[df_feb_sums['bal_out'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_apex = pd.read_csv('../ar_reports/orig/no_neg/apex_ar_no_neg.csv')\n",
    "# df_apex['date'] = pd.to_datetime(df_apex['date'], format=\"%m/%d/%Y\")\n",
    "\n",
    "# df_big_petes = pd.read_csv('../ar_reports/orig/no_neg/big_petes_ar_no_neg.csv')\n",
    "# df_big_petes['date'] = pd.to_datetime(df_big_petes['date'], format=\"%m/%d/%Y\")\n",
    "\n",
    "# df_biscotti = pd.read_csv('../ar_reports/orig/no_neg/biscotti_ar_no_neg.csv')\n",
    "# df_biscotti['date'] = pd.to_datetime(df_biscotti['date'], format=\"%Y/%m/%d\")\n",
    "\n",
    "# df_buddies = pd.read_csv('../ar_reports/orig/no_neg/buddies_ar_no_neg.csv')\n",
    "# df_buddies['date'] = pd.to_datetime(df_buddies['date'], format=\"%m/%d/%Y\")\n",
    "\n",
    "# df_desert_1 = pd.read_csv('../ar_reports/orig/no_neg/desert_road_sum_08_12_19.csv')\n",
    "# df_desert_1['date'] = pd.to_datetime(df_desert_1['date'], format=\"%m/%d/%Y\")\n",
    "\n",
    "# df_desert_2 = pd.read_csv('../ar_reports/orig/no_neg/desert_road_sum_12_31_19.csv')\n",
    "# df_desert_2['date'] = pd.to_datetime(df_desert_2['date'], format=\"%m/%d/%Y\")\n",
    "\n",
    "# df_desert_3 = pd.read_csv('../ar_reports/orig/no_neg/desert_road_sum_02_29_20.csv')\n",
    "# df_desert_3['date'] = pd.to_datetime(df_desert_3['date'], format=\"%m/%d/%Y\")\n",
    "\n",
    "# df_falcon = pd.read_csv('../ar_reports/orig/no_neg/falcon_ar_no_neg.csv')\n",
    "# df_falcon['date'] = pd.to_datetime(df_falcon['date'], format=\"%m/%d/%Y\")\n",
    "\n",
    "# df_headwaters = pd.read_csv('../ar_reports/orig/no_neg/headwaters_ar_no_neg.csv')\n",
    "# df_headwaters['date'] = pd.to_datetime(df_headwaters['date'], format=\"%m/%d/%Y\")\n",
    "\n",
    "# df_flowerhired = pd.read_csv('../ar_reports/orig/no_neg/flowerhired_ar_no_neg.csv')\n",
    "# df_flowerhired['date'] = pd.to_datetime(df_flowerhired['date'], format=\"%m/%d/%Y\")\n",
    "\n",
    "# df_guild = pd.read_csv('../ar_reports/orig/no_neg/guild_extracts_ar_no_neg.csv')\n",
    "# df_guild['date'] = pd.to_datetime(df_guild['date'], format=\"%m/%d/%Y\")\n",
    "\n",
    "# df_henrys = pd.read_csv('../ar_reports/orig/no_neg/henrys_ar_no_neg.csv')\n",
    "# df_henrys['date'] = pd.to_datetime(df_henrys['date'], format=\"%m/%d/%Y\")\n",
    "\n",
    "# df_hf = pd.read_csv('../ar_reports/orig/no_neg/humboldt_ar_no_neg_04_29.csv')\n",
    "# df_hf['date'] = pd.to_datetime(df_hf['date'], format=\"%m/%d/%Y\")\n",
    "\n",
    "# df_kv = pd.read_csv('../ar_reports/orig/no_neg/kiva_ar_no_neg_combined.csv')\n",
    "# df_kv['date'] = pd.to_datetime(df_kv['date'], format=\"%m/%d/%Y\")\n",
    "\n",
    "# df_lob_det = pd.read_csv('../ar_reports/orig/no_neg/LOB_ar_detail_no_neg_3_31_20.csv')\n",
    "# df_lob_det['date'] = pd.to_datetime(df_lob_det['date'], format=\"%m/%d/%Y\")\n",
    "\n",
    "# df_lob_sum = pd.read_csv('../ar_reports/orig/no_neg/LOB_summary_ar_no_neg.csv')\n",
    "# df_lob_sum['date'] = pd.to_datetime(df_lob_sum['date'], format=\"%m/%d/%Y\")\n",
    "\n",
    "# df_nb= pd.read_csv('../ar_reports/orig/no_neg/nabis_ar_no_neg_05_13.csv')\n",
    "# df_nb['date'] = pd.to_datetime(df_nb['date'], format=\"%m/%d/%Y\")\n",
    "\n",
    "# df_sherb= pd.read_csv('../ar_reports/orig/no_neg/sherbinkskis_ar_no_neg.csv')\n",
    "# df_sherb['date'] = pd.to_datetime(df_sherb['date'], format=\"%m/%d/%Y\")\n",
    "\n",
    "# df_shryne= pd.read_csv('../ar_reports/orig/no_neg/shryne_ar_no_neg.csv')\n",
    "# df_shryne['date'] = pd.to_datetime(df_shryne['date'], format=\"%m/%d/%Y\")\n",
    "\n",
    "# df_thirty_one= pd.read_csv('../ar_reports/orig/no_neg/thirty_one_labs_ar_no_neg.csv')\n",
    "# df_thirty_one['date'] = pd.to_datetime(df_thirty_one['date'], format=\"%m/%d/%Y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_ar = df_apex.append(df_big_petes)\n",
    "# df_ar = df_ar.append(df_biscotti)\n",
    "# df_ar = df_ar.append(df_buddies)\n",
    "# df_ar = df_ar.append(df_desert_1)\n",
    "# df_ar = df_ar.append(df_desert_2)\n",
    "# df_ar = df_ar.append(df_desert_3)\n",
    "# df_ar = df_ar.append(df_headwaters)\n",
    "# df_ar = df_ar.append(df_flowerhired)\n",
    "# df_ar = df_ar.append(df_guild)\n",
    "# df_ar = df_ar.append(df_henrys)\n",
    "# df_ar = df_ar.append(df_hf)\n",
    "# df_ar = df_ar.append(df_kv)\n",
    "# df_ar = df_ar.append(df_lob_det)\n",
    "# df_ar = df_ar.append(df_lob_sum)\n",
    "# df_ar = df_ar.append(df_nb)\n",
    "# df_ar = df_ar.append(df_sherb)\n",
    "# df_ar = df_ar.append(df_shryne)\n",
    "# df_ar = df_ar.append(df_thirty_one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(df_all[df_all['client'] == 'Apex']['license_number'].unique())\n",
    "# len(df_all[df_all['client'] == 'Apex']['roll_up_id'].unique())\n",
    "# len(df_all[df_all['client'] == 'Big Petes'])\n",
    "# len(df_all[df_all['client'] == 'Big Petes']['license_number'].unique())\n",
    "# len(df_all[df_all['client'] == 'Big Petes']['roll_up_id'].unique())\n",
    "# len(df_all[df_all['client'] == 'Beezle'])\n",
    "# len(df_all[df_all['client'] == 'Beezle']['license_number'].unique())\n",
    "# len(df_all[df_all['client'] == 'Beezle']['roll_up_id'].unique())\n",
    "# len(df_all[df_all['client'] == 'Biscotti'])\n",
    "# len(df_all[df_all['client'] == 'Biscotti']['license_number'].unique())\n",
    "# len(df_all[df_all['client'] == 'Biscotti']['roll_up_id'].unique())\n",
    "# len(df_all[df_all['client'] == 'Buddies']['license_number'].unique())\n",
    "# len(df_all[df_all['client'] == 'Buddies']['roll_up_id'].unique())\n",
    "# len(df_all[df_all['client'] == 'Chemistry'])\n",
    "# len(df_all[df_all['client'] == 'Chemistry']['license_number'].unique())\n",
    "# len(df_all[df_all['client'] == 'Chemistry']['roll_up_id'].unique())\n",
    "# len(df_all[df_all['client'] == 'Desert Road']['license_number'].unique())\n",
    "# len(df_all[df_all['client'] == 'Desert Road']['roll_up_id'].unique())\n",
    "# len(df_all[df_all['client'] == 'DomPen'])\n",
    "# len(df_all[df_all['client'] == 'DomPen']['license_number'].unique())\n",
    "# len(df_all[df_all['client'] == 'DomPen']['roll_up_id'].unique())\n",
    "# len(df_all[df_all['client'] == 'Falcon'])\n",
    "# len(df_all[df_all['client'] == 'Falcon']['license_number'].unique())\n",
    "# len(df_all[df_all['client'] == 'Falcon']['roll_up_id'].unique())\n",
    "# len(df_all[df_all['client'] == 'Flowerhired'])\n",
    "# len(df_all[df_all['client'] == 'Flowerhired']['license_number'].unique())\n",
    "# len(df_all[df_all['client'] == 'Flowerhired']['roll_up_id'].unique())\n",
    "# len(df_all[df_all['client'] == 'Guild Extracts'])\n",
    "# len(df_all[df_all['client'] == 'Guild Extracts']['license_number'].unique())\n",
    "# len(df_all[df_all['client'] == 'Guild Extracts']['roll_up_id'].unique())\n",
    "# len(df_all[df_all['client'] == 'Headwaters']['license_number'].unique())\n",
    "# len(df_all[df_all['client'] == 'Headwaters']['roll_up_id'].unique())\n",
    "# len(df_all[df_all['client'] == 'Henrys']['license_number'].unique())\n",
    "# len(df_all[df_all['client'] == 'Henrys']['roll_up_id'].unique())\n",
    "# len(df_all[df_all['client'] == 'Humboldt Farms']['license_number'].unique())\n",
    "# len(df_all[df_all['client'] == 'Humboldt Farms']['roll_up_id'].unique())\n",
    "# len(df_all[df_all['client'] == 'Kiva']['license_number'].unique())\n",
    "# len(df_all[df_all['client'] == 'Kiva']['roll_up_id'].unique())\n",
    "# len(df_all[df_all['client'] == 'Left Coast Ventures'])\n",
    "# len(df_all[df_all['client'] == 'Left Coast Ventures']['license_number'].unique())\n",
    "# len(df_all[df_all['client'] == 'Left Coast Ventures']['roll_up_id'].unique())\n",
    "# len(df_all[df_all['client'] == 'LOB']['license_number'].unique())\n",
    "# len(df_all[df_all['client'] == 'LOB']['roll_up_id'].unique())\n",
    "# len(df_all[df_all['client'] == 'Leune'])\n",
    "# len(df_all[df_all['client'] == 'Leune']['license_number'].unique())\n",
    "# len(df_all[df_all['client'] == 'Leune']['roll_up_id'].unique())\n",
    "# len(df_all[df_all['client'] == 'Nabis']['license_number'].unique())\n",
    "# len(df_all[df_all['client'] == 'Nabis']['roll_up_id'].unique())\n",
    "# len(df_all[df_all['client'] == 'Sherbinkskis'])\n",
    "# len(df_all[df_all['client'] == 'Sherbinkskis']['license_number'].unique())\n",
    "# len(df_all[df_all['client'] == 'Sherbinkskis']['roll_up_id'].unique())\n",
    "# len(df_all[df_all['client'] == 'Shryne']['license_number'].unique())\n",
    "# len(df_all[df_all['client'] == 'Shryne']['roll_up_id'].unique())\n",
    "# len(df_all[df_all['client'] == 'Thirty One Labs']['license_number'].unique())\n",
    "# len(df_all[df_all['client'] == 'Thirty One Labs']['roll_up_id'].unique())\n",
    "# len(df_all[df_all['client'] == 'Tri-State Distribution'])\n",
    "# len(df_all[df_all['client'] == 'Tri-State Distribution']['license_number'].unique())\n",
    "# len(df_all[df_all['client'] == 'Tri-State Distribution']['roll_up_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_all[df_all['client'] == 'Apex']['date'].unique()\n",
    "\n",
    "# df_all[(df_all['date'] == pd.Timestamp(date(2020, 3, 31))) & (df_all['client']== 'Apex')]['bal_out'].sum()\n",
    "\n",
    "# df_all[(df_all['date'] == pd.Timestamp(date(2020, 4, 27))) & (df_all['client']== 'Beezle')]['bal_out'].sum()l\n",
    "\n",
    "# df_all[df_all['client'] == 'Big Petes']['date'].unique()\n",
    "\n",
    "# df_all[(df_all['date'] == pd.Timestamp(date(2019, 9, 30))) & (df_all['client']== 'Big Petes')]['bal_out'].sum()\n",
    "# df_all[df_all['client'] == 'Biscotti']['date'].unique()\n",
    "# df_all[df_all['client']== 'Biscotti']['bal_out'].sum()\n",
    "# df_all[df_all['client'] == 'Buddies']['date'].unique()\n",
    "# df_all[(df_all['date'] == pd.Timestamp(date(2020, 5, 31))) & (df_all['client']== 'Buddies')]['bal_out'].sum()\n",
    "# df_all[df_all['client']== 'Chemistry']['bal_out'].sum()\n",
    "# df_all[df_all['client']== 'DomPen']['bal_out'].sum()\n",
    "# df_all[df_all['client'] == 'Desert Road']['date'].unique()\n",
    "# df_all[(df_all['date'] == pd.Timestamp(date(2020, 2, 29))) & (df_all['client']== 'Desert Road')]['bal_out'].sum()\n",
    "# df_all[df_all['client'] == 'Flowerhired']['date'].unique()\n",
    "# df_all[(df_all['date'] == pd.Timestamp(date(2020, 6, 30))) & (df_all['client']== 'Flowerhired')]['bal_out'].sum()\n",
    "# df_all[df_all['client'] == 'Guild Extracts']['date'].unique()\n",
    "# df_all[(df_all['date'] == pd.Timestamp(date(2020, 3, 31))) & (df_all['client']== 'Guild Extracts')]['bal_out'].sum()\n",
    "# df_all[df_all['client'] == 'Headwaters']['date'].unique()\n",
    "# df_all[(df_all['date'] == pd.Timestamp(date(2020, 6, 30))) & (df_all['client']== 'Headwaters')]['bal_out'].sum()\n",
    "# df_all[df_all['client'] == 'Henrys']['date'].unique()\n",
    "# df_all[(df_all['date'] == pd.Timestamp(date(2019, 11, 11))) & (df_all['client']== 'Henrys')]['bal_out'].sum()\n",
    "# df_all[df_all['client'] == 'Humboldt Farms']['date'].unique()\n",
    "# df_all[(df_all['date'] == pd.Timestamp(date(2020, 3, 31))) & (df_all['client']== 'Humboldt Farms')]['bal_out'].sum()\n",
    "# df_all[df_all['client'] == 'Kiva']['date'].unique()\n",
    "# df_all[(df_all['date'] == pd.Timestamp(date(2020, 2, 25))) & (df_all['client']== 'Kiva')]['bal_out'].sum()\n",
    "# df_all[df_all['client']== 'Left Coast Ventures']['bal_out'].sum()\n",
    "# df_all[(df_all['date'] == pd.Timestamp(date(2019, 9, 30))) & (df_all['client']== 'Left Coast Ventures')]['bal_out'].sum()\n",
    "# df_all[df_all['client']== 'Leune']['bal_out'].sum()\n",
    "# df_all[df_all['client']== 'Tri-State Distribution']['bal_out'].sum()\n",
    "# df_all[(df_all['date'] == pd.Timestamp(date(2020, 4, 10))) & (df_all['client']== 'LOB')]['bal_out'].sum()\n",
    "# df_all[(df_all['date'] == pd.Timestamp(date(2020, 3, 31))) & (df_all['client']== 'Nabis')]['bal_out'].sum()\n",
    "# df_all[df_all['client'] == 'Sherbinkskis']['date'].unique()\n",
    "# df_all[df_all['client'] == 'Shryne']['date'].unique()\n",
    "# df_all[(df_all['date'] == pd.Timestamp(date(2019, 1, 29))) & (df_all['client']== 'Shryne')]['bal_out'].sum()\n",
    "# df_all[df_all['client'] == 'Thirty One Labs']['date'].unique()\n",
    "# df_all[(df_all['date'] == pd.Timestamp(date(2020, 6, 30))) & (df_all['client']== 'Thirty One Labs')]['bal_out'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[[‘InvoiceDate’, ‘Quantity’]].groupby(df[‘InvoiceDate’].dt.date).sum().sort_values(by=’Quantity’, ascending=False).head()\n",
    "\n",
    "# df_all[['client', 'date', 'bal_out']].groupby(df_all['date'].dt.date).sum().sort_values(by='bal_out', ascending=False).head()\n",
    "\n",
    "# df_all[['client', 'date', 'bal_out']].groupby('client', as_index=False).max().sort_values(by='bal_out', ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(df_ar_roll[df_ar_roll['delinquent'] == 1])\n",
    "# df_ar_roll[df_ar_roll['license_number'] == '0']\n",
    "# df_ar_roll[(df_ar_roll['roll_up_id'].isnull()) & (df_ar_roll['license_number'] == '0')]\n",
    "# df_ar_roll[df_ar_roll['license_number'] == '0']\n",
    "# df_ar_roll[(df_ar_roll['roll_up_id'].isnull()) & (df_ar_roll['license_number'] != '0')]\n",
    "# df_ar_roll.to_csv('../credit_score_files/df_ar_roll_all.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
